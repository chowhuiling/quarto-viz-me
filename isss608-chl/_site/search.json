[
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06_Horizon_Plot.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06_Horizon_Plot.html",
    "title": "Horizon Plot",
    "section": "",
    "text": "Getting started\nIn this section, you will learn how to plot a horizon graph by using ggHoriPlot package.\n\n\n\n\n\n\nTip\n\n\n\nBefore getting started, please visit Getting Started to learn more about the functions of ggHoriPlot package. Next, read geom_horizon() to learn more about the usage of its arguments.\n\n\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, Average Retail Prices Of Selected Consumer Items will be used.\nUse the code chunk below to import the AVERP.csv file into R environment.\n\n\n\n\n\n\nThing to learn from the code chunk above.\n\n\n\n\nBy default, read_csv will import data in Date field as Character data type. dmy() of lubridate package to palse the Date field into appropriate Date data type in R.\n\n\n\n\n\nStep 2: Plotting the horizon graph\nNext, the code chunk below will be used to plot the horizon graph. Take note that we added #| fig-width: 12 and #| fig-width: 10 to control the size of the figure"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "OECD education director Andreas Schleicher shared in a BBC article that “Singapore managed to achieve excellence without wide differences between children from wealthy and disadvantaged families.” (2016) Furthermore, several Singapore’s Minister for Education also started an “every school a good school” slogan. The general public, however, strongly belief that there are still disparities that exist, especially between the elite schools and neighborhood school, between students from families with higher socioeconomic status and those with relatively lower socioeconomic status and immigration and non-immigration families.\n\n\n\nThe 2022 Programme for International Student Assessment (PISA) data was released on December 5, 2022. PISA global education survey every three years to assess the education systems worldwide through testing 15 year old students in the subjects of mathematics, reading, and science.\nIn this take-home exercise, you are required to use appropriate Exploratory Data Analysis (EDA) methods and ggplot2 functions to reveal:\n\nthe distribution of Singapore students’ performance in mathematics, reading, and science, and\nthe relationship between these performances with schools, gender and socioeconomic status of the students.\n\nLimit your submission to not more than five EDA visualisation.\nThe writeup should contain:\n\nA reproducible description of the procedures used to prepare the analytical visualisation. Please refer to the senior submission I shared below.\nA write-up of not more than 150 words to describe and discuss the patterns reveal by each EDA visualisation prepared.\n\n\n\n\nThe PISA 2022 database contains the full set of responses from individual students, school principals and parents. There are a total of five data files and their contents are as follows:\n\nStudent questionnaire data file\nSchool questionnaire data file\nTeacher questionnaire data file\nCognitive item data file\nQuestionnaire timing data file\n\nThese data files are in SAS and SPSS formats. For the purpose of this assignment, you are required to use the Student questionnaire data file only. However, you are encouraged to download the other files for future needs.\nBesides the data files, you will find a collection of complementary materials such as questionnaires, codebooks, compendia and the rescaled indices for trend analyses in this page too.\nTo learn more about PISA 2022 survey, you are encouraged to consult PISA 2022 Technical Report\n\n\n\n\n\nProcess the data using  tidyverse packages\nStatistical graphics must be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#context",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#context",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "OECD education director Andreas Schleicher shared in a BBC article that “Singapore managed to achieve excellence without wide differences between children from wealthy and disadvantaged families.” (2016) Furthermore, several Singapore’s Minister for Education also started an “every school a good school” slogan. The general public, however, strongly belief that there are still disparities that exist, especially between the elite schools and neighborhood school, between students from families with higher socioeconomic status and those with relatively lower socioeconomic status and immigration and non-immigration families."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#task",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#task",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "The 2022 Programme for International Student Assessment (PISA) data was released on December 5, 2022. PISA global education survey every three years to assess the education systems worldwide through testing 15 year old students in the subjects of mathematics, reading, and science.\nIn this take-home exercise, you are required to use appropriate Exploratory Data Analysis (EDA) methods and ggplot2 functions to reveal:\n\nthe distribution of Singapore students’ performance in mathematics, reading, and science, and\nthe relationship between these performances with schools, gender and socioeconomic status of the students.\n\nLimit your submission to not more than five EDA visualisation.\nThe writeup should contain:\n\nA reproducible description of the procedures used to prepare the analytical visualisation. Please refer to the senior submission I shared below.\nA write-up of not more than 150 words to describe and discuss the patterns reveal by each EDA visualisation prepared."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-data",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#the-data",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "The PISA 2022 database contains the full set of responses from individual students, school principals and parents. There are a total of five data files and their contents are as follows:\n\nStudent questionnaire data file\nSchool questionnaire data file\nTeacher questionnaire data file\nCognitive item data file\nQuestionnaire timing data file\n\nThese data files are in SAS and SPSS formats. For the purpose of this assignment, you are required to use the Student questionnaire data file only. However, you are encouraged to download the other files for future needs.\nBesides the data files, you will find a collection of complementary materials such as questionnaires, codebooks, compendia and the rescaled indices for trend analyses in this page too.\nTo learn more about PISA 2022 survey, you are encouraged to consult PISA 2022 Technical Report"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#designing-tools",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#designing-tools",
    "title": "In-class Exercise 1",
    "section": "",
    "text": "Process the data using  tidyverse packages\nStatistical graphics must be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#version-1",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#version-1",
    "title": "In-class Exercise 1",
    "section": "Version 1",
    "text": "Version 1\n\nLoading R Packages\nIn this hands-on exercise, two R packages will be used. They are:\n\ntidyverse ; and\nhaven\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse,haven)\n\nNote: using pacman::p_load() instead of p_load() allows us to use the p_load libary in pacman package even if pacman is not installed.\nThe code chunk below uses read_sas() of haven to import PISA data into R envionment.\n\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")\n\nInterpreting the results: 613744 obs. of 1279 variables means there are 613744 observations, with 1279 columns in the data.\nread_sas() is better than read.sas() because read_sas conforms to tibbler dataframe and retains the column descriptions (aka column labels) in addition to just the variable names\nUse the data explorer to filter CNT by SGP to get only Singapore data\nread_sas() is better than read.sas() because read_sas conforms to tibbler dataframe and retains the column descriptions (aka column labels) in addition to just the variable names\nUse the data explorer to filter CNT by SGP to get only Singapore data\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\nwrite the filtered data into a .rds file\n\nwrite_rds(stu_qqq_SG, \"data/stu_qqq_SG.rds\")\n\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")\n\n\n\n\nA write-up of not more than 150 words to describe and discuss the patterns reveal by each EDA visualisation prepared.\n(One visualisation may contain multiple charts in a single patchwork to tell a story)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "Problem DescriptionSolution\n\n\n\n\nAccording to an office report as shown in the infographic below,\n\nDaily mean temperature are projected to increase by 1.4 to 4.6, and\nThe contrast between the wet months (November to January) and dry month (February and June to September) is likely to be more pronounced.\n\n\n\n\nReference Climate report infographic\n\n\n\n\n\nIn this take-home exercise, you are required to:\nSelect a weather station and download historical daily temperature or rainfall data from Meteorological Service Singapore website, Select either daily temperature or rainfall records of a month of the year 1983, 1993, 2003, 2013 and 2023 and create an analytics-driven data visualisation, Apply appropriate interactive techniques to enhance the user experience in data discovery and/or visual story-telling.\n\n\n\n\n\nDaily Temperature of January in the years 1983, 1993, 2003, 2013, 2023 in Changi Station.\nChangi Station is selected as it contains all the temperature data (mean, max, min) all the way from 1982 to current according to the Station Records.\n\n\n\nThe data is retrieved from http://www.weather.gov.sg/files/dailydata/DAILYDATA_S&lt;STN&gt;_YYYYMM.csv, where &lt;STN&gt; represents the location of the stations and YYYY is the year and MM is the month. STN for Changi is 24. Below is the code used to retrieve the csv files:\nFirst, install and load the required package: - curl for downloading csv files from website - tidyverse for data manipulation - lubridate for extracting week and day numbers from date field - ggthemes is to remove chart junk - patchwork is to combine multiple plots into one - ggiraph for inteeractive plot\n\n# Install and load the required packages\npacman::p_load(curl, tidyverse, knitr, lubridate, ggthemes, patchwork, ggiraph)\n\nNext, download the csv files into the data folder (the data folder should be available):\n\n# Set the base URL template\nbase_url &lt;- \"http://www.weather.gov.sg/files/dailydata/\"\n\n# Create a function to crawl and save data\ndownload_and_save &lt;- function(stn, yyyymm) {\n  # Construct the URL\n  csv_url &lt;- paste0(base_url, \"DAILYDATA_S\",stn,\"_\",yyyymm,\".csv\")\n\n  # Specify the local path where you want to save the downloaded file\n  local_path &lt;- sub(base_url, \"data/\", csv_url)\n  \n  # Use curl_download to download the file\n  curl_download(url = csv_url, destfile = local_path, quiet = FALSE)\n  return (local_path)\n}\n\n#initialize empty vector to add the local paths of downloaded csvs\ncsv_paths = c()\n# Loop over year and month values\n\nfor (year in seq(1983,2023, by=10)) {\n  for (month in 01) {\n    if (month &lt; 10) {\n      mth &lt;- paste(\"0\",month, sep=\"\")\n    }\n    else {\n      mth &lt;- month\n    }\n    yyyymm &lt;- paste(year,mth,sep = \"\")\n    csv_paths &lt;- append(csv_paths, download_and_save(stn = \"24\", yyyymm = yyyymm))\n  } #end loop month\n} # end loop year\ncsv_paths\n\nThen, load the data from the csv files. We use the following code chunk to determine the filenames that need to be loaded:\n\ncsv_files = list.files(path = \"data\", pattern = \"\\\\.csv$\", full.names = TRUE)\n\ncsv_files\n\n[1] \"data/DAILYDATA_S24_198301.csv\" \"data/DAILYDATA_S24_199301.csv\"\n[3] \"data/DAILYDATA_S24_200301.csv\" \"data/DAILYDATA_S24_201301.csv\"\n[5] \"data/DAILYDATA_S24_202301.csv\"\n\n\nHere we need to set the locale to use encoding=\"WINDOWS-1252\", in order to avoid the encoding error that results in invalid multibyte string error. Also ignore Rainfall and Wind columns. Below code chunk does not work because the files have slightly different column naming conventions.\n\n#the below code doesn't work because some columns are not named exactly the same.\ninput_data &lt;- read_csv(csv_files, \n                       id = \"file\",\n                       col_select = -contains(c(\"ainfall\",\"Wind\")),\n                       locale = locale(encoding=\"WINDOWS-1252\")\n                       )\n#input_data\n# \n# # Use the first csv to determine the column types, skipping the rainfall column\n# data &lt;- read_csv(csv_paths[1],\n#                  col_select = -contains(c(\"ainfall\")),\n#                  locale = locale(encoding=\"WINDOWS-1252\")\n#                  )\n# print(colnames(data))\n# \n# head(data,5)\n\nThis code chunk below is used instead. We loop through the filepaths and read the csvs using certain locale, specifying only certain columns. Columns are renamed for ease of analysis and an additional date field is added. The dataset obtained are merged using dplyr::bind_rows and stored as cleaned_df.\n\n#instead, we try to read one by one and skip the problematic rainfall columns.\nread_csv_skip_rainfall &lt;- function(path) {\n\n# # Adding index column \n# data &lt;- data[with(data, order(Year, Day)), ]\n# data$Index &lt;- seq(from=1, to=nrow(data))\n# \n# head(data, 5)\n  \n  \n  \n  temp_data &lt;- read_csv(path,\n                   col_select = -contains(c(\"ainfall\",\"Wind\")),\n                   locale = locale(encoding=\"WINDOWS-1252\")\n                          )\n  #normalise the column names and replace the weird characters\n  old_colnames &lt;- colnames(temp_data)\n  #print(old_colnames)\n  new_colnames &lt;- gsub(pattern=\"[Â°C\\\\)]| \\\\(\", replacement=\"\", colnames(temp_data))\n  new_colnames &lt;- tolower(gsub(pattern=\" \", \n                               replacement = \"_\", \n                               x = new_colnames, \n                               perl = FALSE))\n  #print(new_colnames)\n  colnames(temp_data) &lt;- new_colnames\n  \n  \n  #print(temp_data)\n  #print(spec(temp_data))\n  #problems(temp_data)\n  \n  # Add date column \n  temp_data$date &lt;- as.Date(with(temp_data, paste(year, month, day,sep=\"-\")), \"%Y-%m-%d\")\n\n  #review structure of the data\n  return (temp_data)\n}\n\n# Read and process each CSV file\nlist_of_dataframes &lt;- lapply(csv_files, read_csv_skip_rainfall)\ncleaned_df &lt;- dplyr::bind_rows(list_of_dataframes)\nkable(head(cleaned_df))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstation\nyear\nmonth\nday\nmean_temperature\nmaximum_temperature\nminimum_temperature\ndate\n\n\n\n\nChangi\n1983\n1\n1\n26.5\n28.7\n25.1\n1983-01-01\n\n\nChangi\n1983\n1\n2\n26.8\n30.6\n24.8\n1983-01-02\n\n\nChangi\n1983\n1\n3\n27.0\n31.3\n24.5\n1983-01-03\n\n\nChangi\n1983\n1\n4\n27.3\n30.8\n25.0\n1983-01-04\n\n\nChangi\n1983\n1\n5\n27.1\n31.8\n23.7\n1983-01-05\n\n\nChangi\n1983\n1\n6\n27.2\n32.1\n23.7\n1983-01-06\n\n\n\n\n#print(cleaned_df)\n\n\n\n\nTo determine if there are any trends in changes in daily temperature, we use violin plot to show the min, mean and max of temperatures. The median of each temperature statistic is shown in as a line in the violin plot.\n\n#TODO: verify how to add the mean and median labels\n\nggplot(data=cleaned_df,\n       aes(x=as.factor(year))) +\n       geom_violin(aes(y=mean_temperature, group=year, color=\"Mean\", fill=\"Mean\"),\n                    alpha=0.5, draw_quantiles = c(0.5), \n                    position = position_dodge(width = 0.75)) +\n      geom_violin(alpha=0.5, draw_quantiles = c(0.5),  \n                   aes(y=maximum_temperature, group=year, color=\"Max\", fill=\"Max\"),\n                   position = position_dodge(width = 0.75)) +\n      geom_violin(alpha=0.5, draw_quantiles = c(0.5), \n                   aes(y=minimum_temperature, group = year, color=\"Min\", fill=\"Min\"),\n                   position = position_dodge(width = 0.75)) +\n      \n  #    stat_summary(aes(y = maximum_temperature, group = year), geom = \"pointrange\", fun = \"median\", color = \"black\", size = 0.11, width = 0.2) +\n  stat_summary(aes(y=maximum_temperature,group = year), geom = \"crossbar\", fun = \"mean\", color = \"black\", size = 1, width = 0.2) +\n#  stat_summary(aes(y= maximum_temperature,group = year), geom = \"crossbar\", fun = function(x) quantile(x, 0.75), color = \"Max\", size = 1, width = 0.2) +\n#   stat_summary(aes(y=maximum_temperature, group=group, label = sprintf(\"Median: %.2f\", median(maximum_temperature))), geom = \"text\", vjust = -1, color = \"black\", size = 3) +\n#  stat_summary(aes(y=maximum_temperature, group=year, label = sprintf(\"Mean: %.2f\", mean(..y..))),fun=\"mean\", geom = \"text\", vjust = 1, color = \"red\", size = 3) +\n  \n  labs(title = \"Mean, Min, and Max Daily Temperatures in January for each year\",\n       x = \"Year\",\n       y = \"Temperature (°C)\", \n       fill = \"Daily Temperature Stats\",\n       color = \"Daily Temperature Stats\"\n       ) +\n  scale_fill_manual(values = c(\"Min\" = \"lightblue\", \"Mean\" = \"lightgreen\", \"Max\" = \"lightcoral\"), name = \"Year\") +\n  scale_y_continuous(breaks = seq(0, max(cleaned_df$maximum_temperature), by = 1))+\n  #combine the color and fill as a single legend\n  guides(fill = guide_legend(title = \"Daily Temperature Stats\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWhen we look at the plot, we notice that the mean, max and min daily temperatures seem to be overlapping increasingly over the years (i.e. the total area of overlap between two or more colours is increasing) from 1983 to 2023. In 2013 and 2023, the minimum daily temperature of hotter days can be hotter than the maximum daily temperature of colder days. This suggests that in a single month, the daily temperatures can vary over a wide range and is less predictable than before, as compared to 1983, when the min, mean and max daily temperatures were more distinct. In Jan 2023, we can also see that the mean and max temperatures are becoming more rectangular, which suggests that there is decreasing variant in the mean and max daily temperatures.\nNote that we do not know when are the colder days in the month from this plot, and we cannot confirm whether the colder weather from Dec is coming later in Jan. If that hypothesis is true, the first few days of the month should be when the colder days occur.\nTo investigate further, we plot a calendar heatmap chart to represent the mean, max and min temperature of the different days. We can hover over the tiles to find the temperatures that are the same as the chosen tile.\nNote: The wday() and week() functions from the lubridate package are used to extract the day of the week and week number, respectively. We also added in the hover effect so we can see the tooltip of actual temperature.\n\ngenerate_tooltip &lt;- function(){\n  \n}\n\nplot_calendar_heatmap &lt;- function (df, temperature_type, desc)  {\n  temperature_plot &lt;- ggplot(df, \n                             aes(x = lubridate::wday(date,TRUE),\n                                 y = week(date), \n                                 fill = temperature_type,                              tooltip=paste0(date,\"\\n\", temperature_type,\"°C\"))\n                             ) +                              geom_tile_interactive(color=\"white\", size=0.1, data_id = temperature_type) +\n  \n    coord_equal() +\n    scale_fill_gradient(low = \"light grey\", high = \"red\", na.value = \"white\") +\n  facet_wrap(~year, ncol = 5) +\n  labs(title = paste( desc, \"Daily Temperature for each Year\"),\n       x = \"Day of Week\",\n       y = \"Week\" ,\n       fill = \"Temperature (°C)\") +\n    theme_tufte() + \n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust=0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 6),\n        legend.title = element_text(size=8),\n        legend.text = element_text(size=6),\n        legend.position = \"none\")\n  \n  return (temperature_plot)\n}\n\n#combine the 3 plots with a common legend at the side\ncombined_plot &lt;- (plot_calendar_heatmap (cleaned_df, cleaned_df$mean_temperature, \"Mean\") + \nplot_calendar_heatmap (cleaned_df, cleaned_df$minimum_temperature, \"Minumum\") +\nplot_calendar_heatmap (cleaned_df, cleaned_df$maximum_temperature, \"Maximum\") +\n  plot_layout(guides = \"collect\", axes = \"collect\", ncol = 1, heights = c(1,1,1)) +\n  theme(legend.position = \"right\")\n)\n\ngirafe(code = print(combined_plot),\n       options = list(\n         opts_hover(css=\"stroke-width: 2px; stroke-height:2px\")#,\n         #opts_hover_inv(css=\"opacity:0.2;\")\n       )\n)\n\n\n\n\n\nWe observe that the cooler days in 2023 are actually towards the end of January, which is hard to explain. More data would probably need to be plotted between 2013 and 2023, and probably over the various months to see if there are any trends in the mean, min and max daily temperatures."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#take-home-exercise-3",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#take-home-exercise-3",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "Problem DescriptionSolution\n\n\n\n\nAccording to an office report as shown in the infographic below,\n\nDaily mean temperature are projected to increase by 1.4 to 4.6, and\nThe contrast between the wet months (November to January) and dry month (February and June to September) is likely to be more pronounced.\n\n\n\n\nReference Climate report infographic\n\n\n\n\n\nIn this take-home exercise, you are required to:\nSelect a weather station and download historical daily temperature or rainfall data from Meteorological Service Singapore website, Select either daily temperature or rainfall records of a month of the year 1983, 1993, 2003, 2013 and 2023 and create an analytics-driven data visualisation, Apply appropriate interactive techniques to enhance the user experience in data discovery and/or visual story-telling.\n\n\n\n\n\nDaily Temperature of January in the years 1983, 1993, 2003, 2013, 2023 in Changi Station.\nChangi Station is selected as it contains all the temperature data (mean, max, min) all the way from 1982 to current according to the Station Records.\n\n\n\nThe data is retrieved from http://www.weather.gov.sg/files/dailydata/DAILYDATA_S&lt;STN&gt;_YYYYMM.csv, where &lt;STN&gt; represents the location of the stations and YYYY is the year and MM is the month. STN for Changi is 24. Below is the code used to retrieve the csv files:\nFirst, install and load the required package: - curl for downloading csv files from website - tidyverse for data manipulation - lubridate for extracting week and day numbers from date field - ggthemes is to remove chart junk - patchwork is to combine multiple plots into one - ggiraph for inteeractive plot\n\n# Install and load the required packages\npacman::p_load(curl, tidyverse, knitr, lubridate, ggthemes, patchwork, ggiraph)\n\nNext, download the csv files into the data folder (the data folder should be available):\n\n# Set the base URL template\nbase_url &lt;- \"http://www.weather.gov.sg/files/dailydata/\"\n\n# Create a function to crawl and save data\ndownload_and_save &lt;- function(stn, yyyymm) {\n  # Construct the URL\n  csv_url &lt;- paste0(base_url, \"DAILYDATA_S\",stn,\"_\",yyyymm,\".csv\")\n\n  # Specify the local path where you want to save the downloaded file\n  local_path &lt;- sub(base_url, \"data/\", csv_url)\n  \n  # Use curl_download to download the file\n  curl_download(url = csv_url, destfile = local_path, quiet = FALSE)\n  return (local_path)\n}\n\n#initialize empty vector to add the local paths of downloaded csvs\ncsv_paths = c()\n# Loop over year and month values\n\nfor (year in seq(1983,2023, by=10)) {\n  for (month in 01) {\n    if (month &lt; 10) {\n      mth &lt;- paste(\"0\",month, sep=\"\")\n    }\n    else {\n      mth &lt;- month\n    }\n    yyyymm &lt;- paste(year,mth,sep = \"\")\n    csv_paths &lt;- append(csv_paths, download_and_save(stn = \"24\", yyyymm = yyyymm))\n  } #end loop month\n} # end loop year\ncsv_paths\n\nThen, load the data from the csv files. We use the following code chunk to determine the filenames that need to be loaded:\n\ncsv_files = list.files(path = \"data\", pattern = \"\\\\.csv$\", full.names = TRUE)\n\ncsv_files\n\n[1] \"data/DAILYDATA_S24_198301.csv\" \"data/DAILYDATA_S24_199301.csv\"\n[3] \"data/DAILYDATA_S24_200301.csv\" \"data/DAILYDATA_S24_201301.csv\"\n[5] \"data/DAILYDATA_S24_202301.csv\"\n\n\nHere we need to set the locale to use encoding=\"WINDOWS-1252\", in order to avoid the encoding error that results in invalid multibyte string error. Also ignore Rainfall and Wind columns. Below code chunk does not work because the files have slightly different column naming conventions.\n\n#the below code doesn't work because some columns are not named exactly the same.\ninput_data &lt;- read_csv(csv_files, \n                       id = \"file\",\n                       col_select = -contains(c(\"ainfall\",\"Wind\")),\n                       locale = locale(encoding=\"WINDOWS-1252\")\n                       )\n#input_data\n# \n# # Use the first csv to determine the column types, skipping the rainfall column\n# data &lt;- read_csv(csv_paths[1],\n#                  col_select = -contains(c(\"ainfall\")),\n#                  locale = locale(encoding=\"WINDOWS-1252\")\n#                  )\n# print(colnames(data))\n# \n# head(data,5)\n\nThis code chunk below is used instead. We loop through the filepaths and read the csvs using certain locale, specifying only certain columns. Columns are renamed for ease of analysis and an additional date field is added. The dataset obtained are merged using dplyr::bind_rows and stored as cleaned_df.\n\n#instead, we try to read one by one and skip the problematic rainfall columns.\nread_csv_skip_rainfall &lt;- function(path) {\n\n# # Adding index column \n# data &lt;- data[with(data, order(Year, Day)), ]\n# data$Index &lt;- seq(from=1, to=nrow(data))\n# \n# head(data, 5)\n  \n  \n  \n  temp_data &lt;- read_csv(path,\n                   col_select = -contains(c(\"ainfall\",\"Wind\")),\n                   locale = locale(encoding=\"WINDOWS-1252\")\n                          )\n  #normalise the column names and replace the weird characters\n  old_colnames &lt;- colnames(temp_data)\n  #print(old_colnames)\n  new_colnames &lt;- gsub(pattern=\"[Â°C\\\\)]| \\\\(\", replacement=\"\", colnames(temp_data))\n  new_colnames &lt;- tolower(gsub(pattern=\" \", \n                               replacement = \"_\", \n                               x = new_colnames, \n                               perl = FALSE))\n  #print(new_colnames)\n  colnames(temp_data) &lt;- new_colnames\n  \n  \n  #print(temp_data)\n  #print(spec(temp_data))\n  #problems(temp_data)\n  \n  # Add date column \n  temp_data$date &lt;- as.Date(with(temp_data, paste(year, month, day,sep=\"-\")), \"%Y-%m-%d\")\n\n  #review structure of the data\n  return (temp_data)\n}\n\n# Read and process each CSV file\nlist_of_dataframes &lt;- lapply(csv_files, read_csv_skip_rainfall)\ncleaned_df &lt;- dplyr::bind_rows(list_of_dataframes)\nkable(head(cleaned_df))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstation\nyear\nmonth\nday\nmean_temperature\nmaximum_temperature\nminimum_temperature\ndate\n\n\n\n\nChangi\n1983\n1\n1\n26.5\n28.7\n25.1\n1983-01-01\n\n\nChangi\n1983\n1\n2\n26.8\n30.6\n24.8\n1983-01-02\n\n\nChangi\n1983\n1\n3\n27.0\n31.3\n24.5\n1983-01-03\n\n\nChangi\n1983\n1\n4\n27.3\n30.8\n25.0\n1983-01-04\n\n\nChangi\n1983\n1\n5\n27.1\n31.8\n23.7\n1983-01-05\n\n\nChangi\n1983\n1\n6\n27.2\n32.1\n23.7\n1983-01-06\n\n\n\n\n#print(cleaned_df)\n\n\n\n\nTo determine if there are any trends in changes in daily temperature, we use violin plot to show the min, mean and max of temperatures. The median of each temperature statistic is shown in as a line in the violin plot.\n\n#TODO: verify how to add the mean and median labels\n\nggplot(data=cleaned_df,\n       aes(x=as.factor(year))) +\n       geom_violin(aes(y=mean_temperature, group=year, color=\"Mean\", fill=\"Mean\"),\n                    alpha=0.5, draw_quantiles = c(0.5), \n                    position = position_dodge(width = 0.75)) +\n      geom_violin(alpha=0.5, draw_quantiles = c(0.5),  \n                   aes(y=maximum_temperature, group=year, color=\"Max\", fill=\"Max\"),\n                   position = position_dodge(width = 0.75)) +\n      geom_violin(alpha=0.5, draw_quantiles = c(0.5), \n                   aes(y=minimum_temperature, group = year, color=\"Min\", fill=\"Min\"),\n                   position = position_dodge(width = 0.75)) +\n      \n  #    stat_summary(aes(y = maximum_temperature, group = year), geom = \"pointrange\", fun = \"median\", color = \"black\", size = 0.11, width = 0.2) +\n  stat_summary(aes(y=maximum_temperature,group = year), geom = \"crossbar\", fun = \"mean\", color = \"black\", size = 1, width = 0.2) +\n#  stat_summary(aes(y= maximum_temperature,group = year), geom = \"crossbar\", fun = function(x) quantile(x, 0.75), color = \"Max\", size = 1, width = 0.2) +\n#   stat_summary(aes(y=maximum_temperature, group=group, label = sprintf(\"Median: %.2f\", median(maximum_temperature))), geom = \"text\", vjust = -1, color = \"black\", size = 3) +\n#  stat_summary(aes(y=maximum_temperature, group=year, label = sprintf(\"Mean: %.2f\", mean(..y..))),fun=\"mean\", geom = \"text\", vjust = 1, color = \"red\", size = 3) +\n  \n  labs(title = \"Mean, Min, and Max Daily Temperatures in January for each year\",\n       x = \"Year\",\n       y = \"Temperature (°C)\", \n       fill = \"Daily Temperature Stats\",\n       color = \"Daily Temperature Stats\"\n       ) +\n  scale_fill_manual(values = c(\"Min\" = \"lightblue\", \"Mean\" = \"lightgreen\", \"Max\" = \"lightcoral\"), name = \"Year\") +\n  scale_y_continuous(breaks = seq(0, max(cleaned_df$maximum_temperature), by = 1))+\n  #combine the color and fill as a single legend\n  guides(fill = guide_legend(title = \"Daily Temperature Stats\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWhen we look at the plot, we notice that the mean, max and min daily temperatures seem to be overlapping increasingly over the years (i.e. the total area of overlap between two or more colours is increasing) from 1983 to 2023. In 2013 and 2023, the minimum daily temperature of hotter days can be hotter than the maximum daily temperature of colder days. This suggests that in a single month, the daily temperatures can vary over a wide range and is less predictable than before, as compared to 1983, when the min, mean and max daily temperatures were more distinct. In Jan 2023, we can also see that the mean and max temperatures are becoming more rectangular, which suggests that there is decreasing variant in the mean and max daily temperatures.\nNote that we do not know when are the colder days in the month from this plot, and we cannot confirm whether the colder weather from Dec is coming later in Jan. If that hypothesis is true, the first few days of the month should be when the colder days occur.\nTo investigate further, we plot a calendar heatmap chart to represent the mean, max and min temperature of the different days. We can hover over the tiles to find the temperatures that are the same as the chosen tile.\nNote: The wday() and week() functions from the lubridate package are used to extract the day of the week and week number, respectively. We also added in the hover effect so we can see the tooltip of actual temperature.\n\ngenerate_tooltip &lt;- function(){\n  \n}\n\nplot_calendar_heatmap &lt;- function (df, temperature_type, desc)  {\n  temperature_plot &lt;- ggplot(df, \n                             aes(x = lubridate::wday(date,TRUE),\n                                 y = week(date), \n                                 fill = temperature_type,                              tooltip=paste0(date,\"\\n\", temperature_type,\"°C\"))\n                             ) +                              geom_tile_interactive(color=\"white\", size=0.1, data_id = temperature_type) +\n  \n    coord_equal() +\n    scale_fill_gradient(low = \"light grey\", high = \"red\", na.value = \"white\") +\n  facet_wrap(~year, ncol = 5) +\n  labs(title = paste( desc, \"Daily Temperature for each Year\"),\n       x = \"Day of Week\",\n       y = \"Week\" ,\n       fill = \"Temperature (°C)\") +\n    theme_tufte() + \n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust=0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 6),\n        legend.title = element_text(size=8),\n        legend.text = element_text(size=6),\n        legend.position = \"none\")\n  \n  return (temperature_plot)\n}\n\n#combine the 3 plots with a common legend at the side\ncombined_plot &lt;- (plot_calendar_heatmap (cleaned_df, cleaned_df$mean_temperature, \"Mean\") + \nplot_calendar_heatmap (cleaned_df, cleaned_df$minimum_temperature, \"Minumum\") +\nplot_calendar_heatmap (cleaned_df, cleaned_df$maximum_temperature, \"Maximum\") +\n  plot_layout(guides = \"collect\", axes = \"collect\", ncol = 1, heights = c(1,1,1)) +\n  theme(legend.position = \"right\")\n)\n\ngirafe(code = print(combined_plot),\n       options = list(\n         opts_hover(css=\"stroke-width: 2px; stroke-height:2px\")#,\n         #opts_hover_inv(css=\"opacity:0.2;\")\n       )\n)\n\n\n\n\n\nWe observe that the cooler days in 2023 are actually towards the end of January, which is hard to explain. More data would probably need to be plotted between 2013 and 2023, and probably over the various months to see if there are any trends in the mean, min and max daily temperatures."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#overview",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "According to an office report as shown in the infographic below,\n\nDaily mean temperature are projected to increase by 1.4 to 4.6, and\nThe contrast between the wet months (November to January) and dry month (February and June to September) is likely to be more pronounced.\n\n\n\n\nReference Climate report infographic"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#the-task",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "In this take-home exercise, you are required to:\nSelect a weather station and download historical daily temperature or rainfall data from Meteorological Service Singapore website, Select either daily temperature or rainfall records of a month of the year 1983, 1993, 2003, 2013 and 2023 and create an analytics-driven data visualisation, Apply appropriate interactive techniques to enhance the user experience in data discovery and/or visual story-telling."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#selected-data-for-analysis",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#selected-data-for-analysis",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "Daily Temperature of January in the years 1983, 1993, 2003, 2013, 2023 in Changi Station.\nChangi Station is selected as it contains all the temperature data (mean, max, min) all the way from 1982 to current according to the Station Records."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#data-preparation",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "The data is retrieved from http://www.weather.gov.sg/files/dailydata/DAILYDATA_S&lt;STN&gt;_YYYYMM.csv, where &lt;STN&gt; represents the location of the stations and YYYY is the year and MM is the month. STN for Changi is 24. Below is the code used to retrieve the csv files:\nFirst, install and load the required package: - curl for downloading csv files from website - tidyverse for data manipulation - lubridate for extracting week and day numbers from date field - ggthemes is to remove chart junk - patchwork is to combine multiple plots into one - ggiraph for inteeractive plot\n\n# Install and load the required packages\npacman::p_load(curl, tidyverse, knitr, lubridate, ggthemes, patchwork, ggiraph)\n\nNext, download the csv files into the data folder (the data folder should be available):\n\n# Set the base URL template\nbase_url &lt;- \"http://www.weather.gov.sg/files/dailydata/\"\n\n# Create a function to crawl and save data\ndownload_and_save &lt;- function(stn, yyyymm) {\n  # Construct the URL\n  csv_url &lt;- paste0(base_url, \"DAILYDATA_S\",stn,\"_\",yyyymm,\".csv\")\n\n  # Specify the local path where you want to save the downloaded file\n  local_path &lt;- sub(base_url, \"data/\", csv_url)\n  \n  # Use curl_download to download the file\n  curl_download(url = csv_url, destfile = local_path, quiet = FALSE)\n  return (local_path)\n}\n\n#initialize empty vector to add the local paths of downloaded csvs\ncsv_paths = c()\n# Loop over year and month values\n\nfor (year in seq(1983,2023, by=10)) {\n  for (month in 01) {\n    if (month &lt; 10) {\n      mth &lt;- paste(\"0\",month, sep=\"\")\n    }\n    else {\n      mth &lt;- month\n    }\n    yyyymm &lt;- paste(year,mth,sep = \"\")\n    csv_paths &lt;- append(csv_paths, download_and_save(stn = \"24\", yyyymm = yyyymm))\n  } #end loop month\n} # end loop year\ncsv_paths\n\nThen, load the data from the csv files. We use the following code chunk to determine the filenames that need to be loaded:\n\ncsv_files = list.files(path = \"data\", pattern = \"\\\\.csv$\", full.names = TRUE)\n\ncsv_files\n\n[1] \"data/DAILYDATA_S24_198301.csv\" \"data/DAILYDATA_S24_199301.csv\"\n[3] \"data/DAILYDATA_S24_200301.csv\" \"data/DAILYDATA_S24_201301.csv\"\n[5] \"data/DAILYDATA_S24_202301.csv\"\n\n\nHere we need to set the locale to use encoding=\"WINDOWS-1252\", in order to avoid the encoding error that results in invalid multibyte string error. Also ignore Rainfall and Wind columns. Below code chunk does not work because the files have slightly different column naming conventions.\n\n#the below code doesn't work because some columns are not named exactly the same.\ninput_data &lt;- read_csv(csv_files, \n                       id = \"file\",\n                       col_select = -contains(c(\"ainfall\",\"Wind\")),\n                       locale = locale(encoding=\"WINDOWS-1252\")\n                       )\n#input_data\n# \n# # Use the first csv to determine the column types, skipping the rainfall column\n# data &lt;- read_csv(csv_paths[1],\n#                  col_select = -contains(c(\"ainfall\")),\n#                  locale = locale(encoding=\"WINDOWS-1252\")\n#                  )\n# print(colnames(data))\n# \n# head(data,5)\n\nThis code chunk below is used instead. We loop through the filepaths and read the csvs using certain locale, specifying only certain columns. Columns are renamed for ease of analysis and an additional date field is added. The dataset obtained are merged using dplyr::bind_rows and stored as cleaned_df.\n\n#instead, we try to read one by one and skip the problematic rainfall columns.\nread_csv_skip_rainfall &lt;- function(path) {\n\n# # Adding index column \n# data &lt;- data[with(data, order(Year, Day)), ]\n# data$Index &lt;- seq(from=1, to=nrow(data))\n# \n# head(data, 5)\n  \n  \n  \n  temp_data &lt;- read_csv(path,\n                   col_select = -contains(c(\"ainfall\",\"Wind\")),\n                   locale = locale(encoding=\"WINDOWS-1252\")\n                          )\n  #normalise the column names and replace the weird characters\n  old_colnames &lt;- colnames(temp_data)\n  #print(old_colnames)\n  new_colnames &lt;- gsub(pattern=\"[Â°C\\\\)]| \\\\(\", replacement=\"\", colnames(temp_data))\n  new_colnames &lt;- tolower(gsub(pattern=\" \", \n                               replacement = \"_\", \n                               x = new_colnames, \n                               perl = FALSE))\n  #print(new_colnames)\n  colnames(temp_data) &lt;- new_colnames\n  \n  \n  #print(temp_data)\n  #print(spec(temp_data))\n  #problems(temp_data)\n  \n  # Add date column \n  temp_data$date &lt;- as.Date(with(temp_data, paste(year, month, day,sep=\"-\")), \"%Y-%m-%d\")\n\n  #review structure of the data\n  return (temp_data)\n}\n\n# Read and process each CSV file\nlist_of_dataframes &lt;- lapply(csv_files, read_csv_skip_rainfall)\ncleaned_df &lt;- dplyr::bind_rows(list_of_dataframes)\nkable(head(cleaned_df))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nstation\nyear\nmonth\nday\nmean_temperature\nmaximum_temperature\nminimum_temperature\ndate\n\n\n\n\nChangi\n1983\n1\n1\n26.5\n28.7\n25.1\n1983-01-01\n\n\nChangi\n1983\n1\n2\n26.8\n30.6\n24.8\n1983-01-02\n\n\nChangi\n1983\n1\n3\n27.0\n31.3\n24.5\n1983-01-03\n\n\nChangi\n1983\n1\n4\n27.3\n30.8\n25.0\n1983-01-04\n\n\nChangi\n1983\n1\n5\n27.1\n31.8\n23.7\n1983-01-05\n\n\nChangi\n1983\n1\n6\n27.2\n32.1\n23.7\n1983-01-06\n\n\n\n\n#print(cleaned_df)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#selection-of-visualisation-techniques-used",
    "href": "Take-home_Ex/Take-home_Ex03/Take-home_Ex03.html#selection-of-visualisation-techniques-used",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "To determine if there are any trends in changes in daily temperature, we use violin plot to show the min, mean and max of temperatures. The median of each temperature statistic is shown in as a line in the violin plot.\n\n#TODO: verify how to add the mean and median labels\n\nggplot(data=cleaned_df,\n       aes(x=as.factor(year))) +\n       geom_violin(aes(y=mean_temperature, group=year, color=\"Mean\", fill=\"Mean\"),\n                    alpha=0.5, draw_quantiles = c(0.5), \n                    position = position_dodge(width = 0.75)) +\n      geom_violin(alpha=0.5, draw_quantiles = c(0.5),  \n                   aes(y=maximum_temperature, group=year, color=\"Max\", fill=\"Max\"),\n                   position = position_dodge(width = 0.75)) +\n      geom_violin(alpha=0.5, draw_quantiles = c(0.5), \n                   aes(y=minimum_temperature, group = year, color=\"Min\", fill=\"Min\"),\n                   position = position_dodge(width = 0.75)) +\n      \n  #    stat_summary(aes(y = maximum_temperature, group = year), geom = \"pointrange\", fun = \"median\", color = \"black\", size = 0.11, width = 0.2) +\n  stat_summary(aes(y=maximum_temperature,group = year), geom = \"crossbar\", fun = \"mean\", color = \"black\", size = 1, width = 0.2) +\n#  stat_summary(aes(y= maximum_temperature,group = year), geom = \"crossbar\", fun = function(x) quantile(x, 0.75), color = \"Max\", size = 1, width = 0.2) +\n#   stat_summary(aes(y=maximum_temperature, group=group, label = sprintf(\"Median: %.2f\", median(maximum_temperature))), geom = \"text\", vjust = -1, color = \"black\", size = 3) +\n#  stat_summary(aes(y=maximum_temperature, group=year, label = sprintf(\"Mean: %.2f\", mean(..y..))),fun=\"mean\", geom = \"text\", vjust = 1, color = \"red\", size = 3) +\n  \n  labs(title = \"Mean, Min, and Max Daily Temperatures in January for each year\",\n       x = \"Year\",\n       y = \"Temperature (°C)\", \n       fill = \"Daily Temperature Stats\",\n       color = \"Daily Temperature Stats\"\n       ) +\n  scale_fill_manual(values = c(\"Min\" = \"lightblue\", \"Mean\" = \"lightgreen\", \"Max\" = \"lightcoral\"), name = \"Year\") +\n  scale_y_continuous(breaks = seq(0, max(cleaned_df$maximum_temperature), by = 1))+\n  #combine the color and fill as a single legend\n  guides(fill = guide_legend(title = \"Daily Temperature Stats\")) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWhen we look at the plot, we notice that the mean, max and min daily temperatures seem to be overlapping increasingly over the years (i.e. the total area of overlap between two or more colours is increasing) from 1983 to 2023. In 2013 and 2023, the minimum daily temperature of hotter days can be hotter than the maximum daily temperature of colder days. This suggests that in a single month, the daily temperatures can vary over a wide range and is less predictable than before, as compared to 1983, when the min, mean and max daily temperatures were more distinct. In Jan 2023, we can also see that the mean and max temperatures are becoming more rectangular, which suggests that there is decreasing variant in the mean and max daily temperatures.\nNote that we do not know when are the colder days in the month from this plot, and we cannot confirm whether the colder weather from Dec is coming later in Jan. If that hypothesis is true, the first few days of the month should be when the colder days occur.\nTo investigate further, we plot a calendar heatmap chart to represent the mean, max and min temperature of the different days. We can hover over the tiles to find the temperatures that are the same as the chosen tile.\nNote: The wday() and week() functions from the lubridate package are used to extract the day of the week and week number, respectively. We also added in the hover effect so we can see the tooltip of actual temperature.\n\ngenerate_tooltip &lt;- function(){\n  \n}\n\nplot_calendar_heatmap &lt;- function (df, temperature_type, desc)  {\n  temperature_plot &lt;- ggplot(df, \n                             aes(x = lubridate::wday(date,TRUE),\n                                 y = week(date), \n                                 fill = temperature_type,                              tooltip=paste0(date,\"\\n\", temperature_type,\"°C\"))\n                             ) +                              geom_tile_interactive(color=\"white\", size=0.1, data_id = temperature_type) +\n  \n    coord_equal() +\n    scale_fill_gradient(low = \"light grey\", high = \"red\", na.value = \"white\") +\n  facet_wrap(~year, ncol = 5) +\n  labs(title = paste( desc, \"Daily Temperature for each Year\"),\n       x = \"Day of Week\",\n       y = \"Week\" ,\n       fill = \"Temperature (°C)\") +\n    theme_tufte() + \n  theme(axis.ticks = element_blank(),\n        plot.title = element_text(hjust=0.5),\n        axis.text.x = element_text(angle = 45, hjust = 1, size = 6),\n        legend.title = element_text(size=8),\n        legend.text = element_text(size=6),\n        legend.position = \"none\")\n  \n  return (temperature_plot)\n}\n\n#combine the 3 plots with a common legend at the side\ncombined_plot &lt;- (plot_calendar_heatmap (cleaned_df, cleaned_df$mean_temperature, \"Mean\") + \nplot_calendar_heatmap (cleaned_df, cleaned_df$minimum_temperature, \"Minumum\") +\nplot_calendar_heatmap (cleaned_df, cleaned_df$maximum_temperature, \"Maximum\") +\n  plot_layout(guides = \"collect\", axes = \"collect\", ncol = 1, heights = c(1,1,1)) +\n  theme(legend.position = \"right\")\n)\n\ngirafe(code = print(combined_plot),\n       options = list(\n         opts_hover(css=\"stroke-width: 2px; stroke-height:2px\")#,\n         #opts_hover_inv(css=\"opacity:0.2;\")\n       )\n)\n\n\n\n\n\nWe observe that the cooler days in 2023 are actually towards the end of January, which is hard to explain. More data would probably need to be plotted between 2013 and 2023, and probably over the various months to see if there are any trends in the mean, min and max daily temperatures."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Note\n\n\n\nNote: Contents of this page are referenced from: instructor’s materials"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#install-and-launching-r-packages",
    "title": "Hands-on Exercise 1",
    "section": "Install and launching R packages",
    "text": "Install and launching R packages\nThe code chunk below uses p_load function of pacman package to check if tidyverse packages have been installed in the computer. If they are, then they will be launched into R environment.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#importing-the-data",
    "title": "Hands-on Exercise 1",
    "section": "Importing the data",
    "text": "Importing the data\nThe code below imports Exam_data.csv into R environment by using read_csv() function in the readr tidyverse package.\n\nexam_data &lt;- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nData contains year end examination grades of a cohort of primary 3 students from a local school.\nThere are a total of seven attributes. chr stands for categorical data (four of them, namely, ID, CLASS, GENDER and RACE). dbl refers to continuous attributes: ENGLISH, MATHS and SCIENCE."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#a-layered-grammar-of-graphics",
    "title": "Hands-on Exercise 1",
    "section": "A Layered Grammar of Graphics",
    "text": "A Layered Grammar of Graphics\nA short description of each building block are as follows:\n\nData: The dataset being plotted.\nAesthetics take attributes of the data and use them to influence visual characteristics, such as position, colours, size, shape, or transparency.\nGeometrics: The visual elements used for our data, such as point, bar or line.\nFacets split the data into subsets to create multiple variations of the same graph (paneling, multiple plots).\nStatistics, statiscal transformations that summarise data (e.g. mean, confidence intervals).\nCoordinate systems define the plane on which data are mapped on the graphic.\nThemes modify all non-data components of a plot, such as main title, sub-title, y-aixs title, or legend background."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "",
    "text": "Note\n\n\n\nNote: Contents of this page are referenced from instructor’s materials: 3 Programming Interactive Data Visualisation with R and 4 Programming Animated Statistical Graphics with R"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#learning-outcome",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Learning Outcome",
    "text": "Learning Outcome\nIn this hands-on exercise, you will learn how to create interactive data visualisation by using functions provided by ggiraph and plotlyr packages."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Getting Started",
    "text": "Getting Started\nFirst, write a code chunk to check, install and launch the following R packages:\n\nggiraph for making ‘ggplot’ graphics interactive.\nplotly, R library for plotting interactive statistical graphs.\nDT provides an R interface to the JavaScript library DataTables that create interactive table on html page.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\npatchwork for combining multiple ggplot2 graphs into one figure.\n\nThe code chunk below will be used to accomplish the task.\n\n\npacman::p_load(ggiraph, plotly, \n               patchwork, DT, tidyverse) \n\n\nImporting Data\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as a tibble data frame called exam_data.\nWe will be re-using the exam_data.csv from Hands-on_Ex01.\nThe code chunk below read_csv() of readr package is used to import exam_data.csv data file into R and save it as a tibble data frame called exam_data.\n\n\nexam_data &lt;- read.csv(\"../Hands-on_Ex01/data/Exam_data.csv\")\n\nhead(exam_data)\n\n          ID CLASS GENDER    RACE ENGLISH MATHS SCIENCE\n1 Student321    3I   Male   Malay      21     9      15\n2 Student305    3I Female   Malay      24    22      16\n3 Student289    3H   Male Chinese      26    16      16\n4 Student227    3F   Male Chinese      27    77      31\n5 Student318    3I   Male   Malay      27    11      25\n6 Student306    3I Female   Malay      31    16      16\n\n\n\n\n\nInteractive Data Visualisation - ggiraph methods\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detailed explanation.\n\nTooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, a ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page.\n\n\n\nInteractivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed.\n\n\n\n\n\n\n\n\nDisplaying multiple information on tooltip\nThe content of the tooltip can be customised by including a list object as shown in the code chunk below.\n\nexam_data$tooltip &lt;- c(paste0(     \n  \"Name = \", exam_data$ID,         \n  \"\\n Class = \", exam_data$CLASS)) \n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip), \n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 8,\n  height_svg = 8*0.618\n)\n\nThe first three lines of codes in the code chunk create a new field called tooltip. At the same time, it populates text in ID and CLASS fields into the newly created field. Next, this newly created field is used as tooltip field as shown in the code of line 7.\n\n\nInteractivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed.\n\n\n\n\n\n\n\n\nCustomising Tooltip style\nCode chunk below uses opts_tooltip() of ggiraph to customize tooltip rendering by add css declarations.\n\ntooltip_css &lt;- \"background-color:white; #&lt;&lt;\nfont-style:bold; color:black;\" #&lt;&lt;\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = ID),                   \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(    #&lt;&lt;\n    opts_tooltip(    #&lt;&lt;\n      css = tooltip_css)) #&lt;&lt;\n)                                        \n\nNotice that the background colour of the tooltip is black and the font colour is white and bold.\n\n\n\n\n\n\n\nRefer to Customizing girafe objects to learn more about how to customise ggiraph objects.\n\n\n\nDisplaying statistics on tooltip\nCode chunk below shows an advanced way to customise tooltip. In this example, a function is used to compute 90% confident interval of the mean. The derived statistics are then displayed in the tooltip.\n\ntooltip &lt;- function(y, ymax, accuracy = .01) {\n  mean &lt;- scales::number(y, accuracy = accuracy)\n  sem &lt;- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point &lt;- ggplot(data=exam_data, \n                   aes(x = RACE),\n) +\n  stat_summary(aes(y = MATHS, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,  \n    fill = \"light blue\"\n  ) +\n  stat_summary(aes(y = MATHS),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  )\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\n\n\n\nHover effect with data_id aesthetic\nCode chunk below shows the second interactive feature of ggiraph, namely data_id.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(           \n    aes(data_id = CLASS),             \n    stackgroups = TRUE,               \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618                      \n)                                        \n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\n\nNote that the default value of the hover css is hover_css = “fill:orange;”.\n\n\nStyling hover effect\nIn the code chunk below, css codes are used to change the highlighting effect.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over.\n\n\n\n\n\n\n\nNote: Different from previous example, in this example the ccs customisation request are encoded directly.\n\n\nCombining tooltip and hover effect\nThere are time that we want to combine tooltip and hover effect on the interactive statistical graph as shown in the code chunk below.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(tooltip = CLASS, \n        data_id = CLASS),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618,\n  options = list(                        \n    opts_hover(css = \"fill: #202020;\"),  \n    opts_hover_inv(css = \"opacity:0.2;\") \n  )                                        \n)                                        \n\n\nInteractivity: Elements associated with a data_id (i.e CLASS) will be highlighted upon mouse over. At the same time, the tooltip will show the CLASS.\n\n\n\n\n\n\n\n\n\nClick effect with onclick\nonclick argument of ggiraph provides hotlink interactivity on the web.\nThe code chunk below shown an example of onclick.\n\nexam_data$onclick &lt;- sprintf(\"window.open(\\\"%s%s\\\")\",\n\"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\",\nas.character(exam_data$ID))\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(onclick = onclick),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +               \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\ngirafe(                                  \n  ggobj = p,                             \n  width_svg = 6,                         \n  height_svg = 6*0.618)                                        \n\n\nInteractivity: Web document link with a data object will be displayed on the web browser upon mouse click.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nNote that click actions must be a string column in the dataset containing valid javascript instructions.\n\n\n\nCoordinated Multiple Views with ggiraph\nCoordinated multiple views methods has been implemented in the data visualisation below.\n\n\n\n\n\n\nNotice that when a data point of one of the dotplot is selected, the corresponding data point ID on the second data visualisation will be highlighted too.\nIn order to build a coordinated multiple views as shown in the example above, the following programming strategy will be used:\n\nAppropriate interactive functions of ggiraph will be used to create the multiple views.\npatchwork function of patchwork package will be used inside girafe function to create the interactive coordinated multiple views.\n\n\np1 &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") +  \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\np2 &lt;- ggplot(data=exam_data, \n       aes(x = ENGLISH)) +\n  geom_dotplot_interactive(              \n    aes(data_id = ID),              \n    stackgroups = TRUE,                  \n    binwidth = 1,                        \n    method = \"histodot\") + \n  coord_cartesian(xlim=c(0,100)) + \n  scale_y_continuous(NULL,               \n                     breaks = NULL)\n\ngirafe(code = print(p1 + p2), \n       width_svg = 6,\n       height_svg = 3,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n         )\n       ) \n\nThe data_id aesthetic is critical to link observations between plots and the tooltip aesthetic is optional but nice to have when mouse over a point."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#importing-data",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Importing Data",
    "text": "Importing Data\nThe code chunk below read_csv() of readr package is used to import Exam_data.csv data file into R and save it as a tibble data frame called exam_data.\nWe will be re-using the exam_data.csv from Hands-on_Ex01.\nThe code chunk below read_csv() of readr package is used to import exam_data.csv data file into R and save it as a tibble data frame called exam_data.\n\n\nexam_data &lt;- read.csv(\"../Hands-on_Ex01/data/Exam_data.csv\")\n\nhead(exam_data)\n\n          ID CLASS GENDER    RACE ENGLISH MATHS SCIENCE\n1 Student321    3I   Male   Malay      21     9      15\n2 Student305    3I Female   Malay      24    22      16\n3 Student289    3H   Male Chinese      26    16      16\n4 Student227    3F   Male Chinese      27    77      31\n5 Student318    3I   Male   Malay      27    11      25\n6 Student306    3I Female   Malay      31    16      16"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---ggiraph-methods",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Interactive Data Visualisation - ggiraph methods",
    "text": "Interactive Data Visualisation - ggiraph methods\nggiraph  is an htmlwidget and a ggplot2 extension. It allows ggplot graphics to be interactive.\nInteractive is made with ggplot geometries that can understand three arguments:\n\nTooltip: a column of data-sets that contain tooltips to be displayed when the mouse is over elements.\nOnclick: a column of data-sets that contain a JavaScript function to be executed when elements are clicked.\nData_id: a column of data-sets that contain an id to be associated with elements.\n\nIf it used within a shiny application, elements associated with an id (data_id) can be selected and manipulated on client and server sides. Refer to this article for more detailed explanation.\n\nTooltip effect with tooltip aesthetic\nBelow shows a typical code chunk to plot an interactive statistical graph by using ggiraph package. Notice that the code chunk consists of two parts. First, a ggplot object will be created. Next, girafe() of ggiraph will be used to create an interactive svg object.\n\np &lt;- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)\n\n\n\n\n\nNotice that two steps are involved. First, an interactive version of ggplot2 geom (i.e. geom_dotplot_interactive()) will be used to create the basic graph. Then, girafe() will be used to generate an svg object to be displayed on an html page."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Interactivity",
    "text": "Interactivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID will be displayed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactivity-1",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Interactivity",
    "text": "Interactivity\nBy hovering the mouse pointer on an data point of interest, the student’s ID and Class will be displayed."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---plotly-methods",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Interactive Data Visualisation - plotly methods!",
    "text": "Interactive Data Visualisation - plotly methods!\nPlotly’s R graphing library create interactive web graphics from ggplot2 graphs and/or a custom interface to the (MIT-licensed) JavaScript library plotly.js inspired by the grammar of graphics. Different from other plotly platform, plot.R is free and open source.\n\nThere are two ways to create interactive graph by using plotly, they are:\n\nby using plot_ly(), and\nby using ggplotly()\n\n\nCreating an interactive scatter plot: plot_ly() method\nThe tabset below shows an example a basic interactive plot created by using plot_ly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nplot_ly(data = exam_data, \n             x = ~MATHS, \n             y = ~ENGLISH)\n\n\n\n\n\n\nWorking with visual variable: plot_ly() method\nIn the code chunk below, color argument is mapped to a qualitative visual variable (i.e. RACE).\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nInteractive:\n\nClick on the colour symbol at the legend.\n\n\n\n\nplot_ly(data = exam_data, \n        x = ~ENGLISH, \n        y = ~MATHS, \n        color = ~RACE)\n\n\n\n\n\n\nCreating an interactive scatter plot: ggplotly() method\nThe code chunk below plots an interactive scatter plot by using ggplotly().\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\np &lt;- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\nNotice that the only extra line you need to include in the code chunk is ggplotly().\n\n\n\n\n\nCoordinated Multiple Views with plotly\nThe creation of a coordinated linked plot by using plotly involves three steps:\n\nhighlight_key() of plotly package is used as shared data.\ntwo scatterplots will be created by using ggplot2 functions.\nlastly, subplot() of plotly package is used to place them next to each other side-by-side.\n\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nClick on a data point of one of the scatterplot and see how the corresponding point on the other scatterplot is selected.\n\n\n\nd &lt;- highlight_key(exam_data)\np1 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\np2 &lt;- ggplot(data=d, \n            aes(x = MATHS,\n                y = SCIENCE)) +\n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nsubplot(ggplotly(p1),\n        ggplotly(p2))\n\n\n\n\nThing to learn from the code chunk:\n\nhighlight_key() simply creates an object of class crosstalk::SharedData.\n\nVisit this link to learn more about crosstalk,"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#interactive-data-visualisation---crosstalk-methods",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Interactive Data Visualisation - crosstalk methods!",
    "text": "Interactive Data Visualisation - crosstalk methods!\nCrosstalk is an add-on to the htmlwidgets package. It extends htmlwidgets with a set of classes, functions, and conventions for implementing cross-widget interactions (currently, linked brushing and filtering).\n\nInteractive Data Table: DT package\n\nA wrapper of the JavaScript Library DataTables\nData objects in R can be rendered as HTML tables using the JavaScript library ‘DataTables’ (typically via R Markdown or Shiny).\n\n\nDT::datatable(exam_data, class= \"compact\")\n\n\n\n\n\n\n\nLinked brushing: crosstalk method\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode chunk below is used to implement the coordinated brushing shown above.\n\nd &lt;- highlight_key(exam_data) \np &lt;- ggplot(d, \n            aes(ENGLISH, \n                MATHS)) + \n  geom_point(size=1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\n\ngg &lt;- highlight(ggplotly(p),        \n                \"plotly_selected\")  \n\ncrosstalk::bscols(gg,               \n                  DT::datatable(d), \n                  widths = 5)        \n\nThings to learn from the code chunk:\n\nhighlight() is a function of plotly package. It sets a variety of options for brushing (i.e., highlighting) multiple plots. These options are primarily designed for linking multiple plotly graphs, and may not behave as expected when linking plotly to another htmlwidget package via crosstalk. In some cases, other htmlwidgets will respect these options, such as persistent selection in leaflet.\nbscols() is a helper function of crosstalk package. It makes it easy to put HTML elements side by side. It can be called directly from the console but is especially designed to work in an R Markdown document. Warning: This will bring in all of Bootstrap!."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Reference",
    "text": "Reference\n\nggiraph\nThis link provides online version of the reference guide and several useful articles. Use this link to download the pdf version of the reference guide.\n\nHow to Plot With Ggiraph\nInteractive map of France with ggiraph\n\nCustom interactive sunbursts with ggplot in R\nThis link provides code example on how ggiraph is used to interactive graphs for Swiss Olympians - the solo specialists.\n\n\n\nplotly for R\n\nGetting Started with Plotly in R\nA collection of plotly R graphs are available via this link.\nCarson Sievert (2020) Interactive web-based data visualization with R, plotly, and shiny, Chapman and Hall/CRC is the best resource to learn plotly for R. The online version is available via this link\nPlotly R Figure Reference provides a comprehensive discussion of each visual representations.\nPlotly R Library Fundamentals is a good place to learn the fundamental features of Plotly’s R API.\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#overview",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Overview",
    "text": "Overview\nWhen telling a visually-driven data story, animated graphics tends to attract the interest of the audience and make deeper impression than static graphics. In this hands-on exercise, you will learn how to create animated data visualisation by using gganimate and plotly r packages. At the same time, you will also learn how to (i) reshape data by using tidyr package, and (ii) process, wrangle and transform data by using dplyr package.\n\nBasic concepts of animation\nWhen creating animations, the plot does not actually move. Instead, many individual plots are built and then stitched together as movie frames, just like an old-school flip book or cartoon. Each frame is a different plot when conveying motion, which is built using some relevant subset of the aggregate data. The subset drives the flow of the animation when stitched back together.\n\n\n\nTerminology\nBefore we dive into the steps for creating an animated statistical graph, it’s important to understand some of the key concepts and terminology related to this type of visualization.\n\nFrame: In an animated line graph, each frame represents a different point in time or a different category. When the frame changes, the data points on the graph are updated to reflect the new data.\nAnimation Attributes: The animation attributes are the settings that control how the animation behaves. For example, you can specify the duration of each frame, the easing function used to transition between frames, and whether to start the animation from the current frame or from the beginning.\n\n\n\n\n\n\n\nTip\n\n\n\nBefore you start making animated graphs, you should first ask yourself: Does it makes sense to go through the effort? If you are conducting an exploratory data analysis, a animated graphic may not be worth the time investment. However, if you are giving a presentation, a few well-placed animated graphics can help an audience connect with your topic remarkably better than static counterparts."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#getting-started-1",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Getting Started",
    "text": "Getting Started\n\nLoading the R packages\nFirst, write a code chunk to check, install and load the following R packages:\n\nplotly, R library for plotting interactive statistical graphs.\ngganimate, an ggplot extension for creating animated statistical graphs.\ngifski converts video frames to GIF animations using pngquant’s fancy features for efficient cross-frame palettes and temporal dithering. It produces animated GIFs that use thousands of colors per frame.\ngapminder: An excerpt of the data available at Gapminder.org. We just want to use its country_colors scheme.\ntidyverse, a family of modern R packages specially designed to support data science, analysis and communication task including creating static statistical graphs.\n\n\npacman::p_load(readxl, gifski, gapminder,\n               plotly, gganimate, tidyverse)\n\n\n\nImporting the data\nIn this hands-on exercise, the Data worksheet from GlobalPopulation Excel workbook will be used.\nWrite a code chunk to import Data worksheet from GlobalPopulation Excel workbook by using appropriate R package from tidyverse family.\nIn this section, GlobalPopulation.xls provided will be used. Using read_xls() of readxl package, import GlobalPopulation.xls into R. ::: {style=“font-size: 1.2em”}\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- readxl::read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_each_(funs(factor(.)), col) %&gt;%\n  mutate(Year = as.integer(Year))\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nread_xls() of readxl package is used to import the Excel worksheet.\nmutate_each_() of dplyr package is used to convert all character data type into factor.\nmutate of dplyr package is used to convert data values of Year field into integer.\n\n\n\nUnfortunately, mutate_each_() was deprecated in dplyr 0.7.0. and funs() was deprecated in dplyr 0.8.0. In view of this, we will re-write the code by using mutate_at() as shown in the code chunk below.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate_at(col, as.factor) %&gt;%\n  mutate(Year = as.integer(Year))\n\nInstead of using mutate_at(), across() can be used to derive the same outputs.\n\ncol &lt;- c(\"Country\", \"Continent\")\nglobalPop &lt;- read_xls(\"data/GlobalPopulation.xls\",\n                      sheet=\"Data\") %&gt;%\n  mutate(across(col, as.factor)) %&gt;%\n  mutate(Year = as.integer(Year))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-gganimate-methods",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Animated Data Visualisation: gganimate methods",
    "text": "Animated Data Visualisation: gganimate methods\ngganimate extends the grammar of graphics as implemented by ggplot2 to include the description of animation. It does this by providing a range of new grammar classes that can be added to the plot object in order to customise how it should change with time.\n\ntransition_*() defines how the data should be spread out and how it relates to itself across time.\nview_*() defines how the positional scales should change along the animation.\nshadow_*() defines how data from other points in time should be presented in the given point in time.\nenter_*()/exit_*() defines how new data should appear and how old data should disappear during the course of the animation.\nease_aes() defines how different aesthetics should be eased during transitions.\n\n\nBuilding a static population bubble plot\nIn the code chunk below, the basic ggplot2 functions are used to create a static bubble plot.\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') \n\n\n\n\n\n\n\n\n\n\n\n\nBuilding the animated bubble plot\nIn the code chunk below,\n\ntransition_time() of gganimate is used to create transition through distinct states in time (i.e. Year).\nease_aes() is used to control easing of aesthetics. The default is linear. Other methods are: quadratic, cubic, quartic, quintic, sine, circular, exponential, elastic, back, and bounce.\n\n\nggplot(globalPop, aes(x = Old, y = Young, \n                      size = Population, \n                      colour = Country)) +\n  geom_point(alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(title = 'Year: {frame_time}', \n       x = '% Aged', \n       y = '% Young') +\n  transition_time(Year) +       \n  ease_aes('linear')          \n\nThe animated bubble chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-plotly",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#animated-data-visualisation-plotly",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Animated Data Visualisation: plotly",
    "text": "Animated Data Visualisation: plotly\nIn Plotly R package, both ggplotly() and plot_ly() support key frame animations through the frame argument/aesthetic. They also support an ids argument/aesthetic to ensure smooth transitions between objects with the same id (which helps facilitate object constancy).\n\nBuilding an animated bubble plot: ggplotly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using ggplotly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\nThe animated bubble plot above includes a play/pause button and a slider component for controlling the animation\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7, \n             show.legend = FALSE) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young')\n\nggplotly(gg)\n\n\n\n\n\n\n\nThings to learn from the code chunk above\n\n\n\n\nAppropriate ggplot2 functions are used to create a static bubble plot. The output is then saved as an R object called gg.\nggplotly() is then used to convert the R graphic object into an animated svg object.\n\n\n\n\n\n\nNotice that although show.legend = FALSE argument was used, the legend still appears on the plot. To overcome this problem, theme(legend.position='none') should be used as shown in the plot and code chunk below.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\ngg &lt;- ggplot(globalPop, \n       aes(x = Old, \n           y = Young, \n           size = Population, \n           colour = Country)) +\n  geom_point(aes(size = Population,\n                 frame = Year),\n             alpha = 0.7) +\n  scale_colour_manual(values = country_colors) +\n  scale_size(range = c(2, 12)) +\n  labs(x = '% Aged', \n       y = '% Young') + \n  theme(legend.position='none')\n\nggplotly(gg)\n\n\n\n\n\n\nBuilding an animated bubble plot: plot_ly() method\nIn this sub-section, you will learn how to create an animated bubble plot by using plot_ly() method.\n\nThe plotThe code chunk\n\n\n\n\n\n\n\n\n\n\n\nbp &lt;- globalPop %&gt;%\n  plot_ly(x = ~Old, \n          y = ~Young, \n          size = ~Population, \n          color = ~Continent,\n          sizes = c(2, 100),\n          frame = ~Year, \n          text = ~Country, \n          hoverinfo = \"text\",\n          type = 'scatter',\n          mode = 'markers'\n          ) %&gt;%\n  layout(showlegend = FALSE)\nbp"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference-1",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#reference-1",
    "title": "Hands-on Exercise 3: Interactivity in Visual Analytics",
    "section": "Reference",
    "text": "Reference\n\nGetting Started\nVisit this link for a very interesting implementation of gganimate by your senior.\nBuilding an animation step-by-step with gganimate.\nCreating a composite gif with multiple gganimate panels"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html",
    "title": "Hands-on Ex 6 – Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "Note\n\n\n\nNote: Contents of this page are referenced from instructor’s materials: 17 Visualising and Analysing Time-oriented Data\nShow the code\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table, CGPfunctions, ggHoriPlot, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#learning-outcome",
    "title": "Hands-on Ex 6 – Visualising and Analysing Time-oriented Data",
    "section": "Learning Outcome",
    "text": "Learning Outcome\nBy the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a slopegraph\nplotting a horizon chart"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#getting-started",
    "title": "Hands-on Ex 6 – Visualising and Analysing Time-oriented Data",
    "section": "Getting Started",
    "text": "Getting Started"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#do-it-yourself",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#do-it-yourself",
    "title": "Hands-on Ex 6 – Visualising and Analysing Time-oriented Data",
    "section": "Do It Yourself",
    "text": "Do It Yourself\nWrite a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-calendar-heatmap",
    "title": "Hands-on Ex 6 – Visualising and Analysing Time-oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmatically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks &lt;- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\ntz field stores time zone of the source IP address.\n\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday &lt;- function(ts, sc, tz) {\n  real_times &lt;- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt &lt;- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\n\n\n\n\n\n\nNote\n\n\n\n\nymd_hms() and hour() are from lubridate package, and\nweekdays() is a base R function.\n\n\n\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels &lt;- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks &lt;- attacks %&gt;%\n  group_by(tz) %&gt;%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %&gt;% \n  ungroup() %&gt;% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\n\n\n\n\n\n\nNote\n\n\n\nBeside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\n\n\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped &lt;- attacks %&gt;% \n  count(wkday, hour) %&gt;% \n  ungroup() %&gt;%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThings to learn from the code chunk\n\n\n\n\na tibble data table called grouped is derived by aggregating the attack by wkday and hour fields.\na new field called n is derived by using group_by() and count() functions.\nna.omit() is used to exclude missing value.\ngeom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles.\ntheme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot.\ncoord_equal() is used to ensure the plot will have an aspect ratio of 1:1.\nscale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\n\n\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nBuilding Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attacks by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country &lt;- count(\n  attacks, source_country) %&gt;%\n  mutate(percent = percent(n/sum(n))) %&gt;%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 &lt;- attacks_by_country$source_country[1:4]\ntop4_attacks &lt;- attacks %&gt;%\n  filter(source_country %in% top4) %&gt;%\n  count(source_country, wkday, hour) %&gt;%\n  ungroup() %&gt;%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %&gt;%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-cycle-plot",
    "title": "Hands-on Ex 6 – Visualising and Analysing Time-oriented Data",
    "section": "Plotting Cycle Plot",
    "text": "Plotting Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair &lt;- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month &lt;- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year &lt;- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam &lt;- air %&gt;% \n  select(`Vietnam`, \n         month, \n         year) %&gt;%\n  filter(year &gt;= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data &lt;- Vietnam %&gt;% \n  group_by(month) %&gt;%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\nSrep 6: Plotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme_tufte(base_family = \"Helvetica\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "href": "Hands-on_Ex/Hands-on_Ex06/Hands-on_Ex06.html#plotting-slopegraph",
    "title": "Hands-on Ex 6 – Visualising and Analysing Time-oriented Data",
    "section": "Plotting Slopegraph",
    "text": "Plotting Slopegraph\nIn this section you will learn how to plot a slopegraph by using R.\nBefore getting start, make sure that CGPfunctions has been installed and loaded onto R environment. Then, refer to Using newggslopegraph to learn more about the function. Lastly, read more about newggslopegraph() and its arguments by referring to this link.\n\nStep 1: Data Import\nImport the rice data set into R environment by using the code chunk below.\n\nrice &lt;- read_csv(\"data/rice.csv\")\n\n\n\nStep 2: Plotting the slopegraph\nNext, code chunk below will be used to plot a basic slopegraph as shown below.\n\nrice %&gt;% \n  mutate(Year = factor(Year)) %&gt;%\n  filter(Year %in% c(1961, 1980)) %&gt;%\n  newggslopegraph(Year, Yield, Country,\n                Title = \"Rice Yield of Top 11 Asian Counties\",\n                SubTitle = \"1961-1980\",\n                Caption = \"Prepared by: Dr. Kam Tin Seong\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThing to learn from the code chunk above\n\n\n\nFor effective data visualisation design, factor() is used convert the value type of Year field from numeric to factor."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Hello! Welcome to ISSS608 Visual Analytics and Applications homepage. In this website, you will find my coursework prepared for this course. Will be adding more along the way.\nThis website is built using Quarto and powered by Netlify."
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "ISSS608-VAA",
    "section": "Resources",
    "text": "Resources\n\nR for Data Science ed 2\nMost of the materials are referenced from the Course website at: https://isss608-ay2023-24jan.netlify.app/"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background-and-context",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#background-and-context",
    "title": "Take-home Exercise 1",
    "section": "Background and Context",
    "text": "Background and Context\nOECD education director Andreas Schleicher shared in a BBC article that “Singapore managed to achieve excellence without wide differences between children from wealthy and disadvantaged families.” (2016) Furthermore, several Singapore’s Minister for Education also started an “every school a good school” slogan. The general public, however, strongly believed that there are still disparities that exist, especially between the elite schools and neighborhood school, between students from families with higher socioeconomic status and those with relatively lower socioeconomic status and immigration and non-immigration families.\nThe 2022 Programme for International Student Assessment (PISA) data was released on December 5, 2022. PISA global education survey every three years to assess the education systems worldwide through testing 15 year old students in the subjects of mathematics, reading, and science."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#task",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#task",
    "title": "Take-home Exercise 1",
    "section": "Task",
    "text": "Task\nIn this take-home exercise, you are required to use appropriate Exploratory Data Analysis (EDA) methods and ggplot2 functions to reveal:\n\nthe distribution of Singapore students’ performance in mathematics, reading, and science, and\nthe relationship between these performances with schools, gender and socioeconomic status of the students.\n\nLimit your submission to not more than five EDA visualisation.\n\nRequirements\nThe writeup should contain:\n\nA reproducible description of the procedures used to prepare the analytical visualisation. Please refer to the senior submission in the reference section.\nA write-up of not more than 150 words to describe and discuss the patterns revealed by each EDA visualisation prepared."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#the-data",
    "title": "Take-home Exercise 1",
    "section": "The Data",
    "text": "The Data\nThe PISA 2022 database contains the full set of responses from individual students, school principals and parents. There are a total of five data files and their contents are as follows:\n\nStudent questionnaire data file\nSchool questionnaire data file\nTeacher questionnaire data file\nCognitive item data file\nQuestionnaire timing data file\n\nThese data files are in SAS and SPSS formats. For the purpose of this assignment, you are required to use the Student questionnaire data file only.\nBesides the data files, you will find a collection of complementary materials such as questionnaires, codebooks, compendia and the rescaled indices for trend analyses in this page too.\nTo learn more about PISA 2022 survey, you are encouraged to consult PISA 2022 Technical Report"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#designing-tools",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#designing-tools",
    "title": "Take-home Exercise 1",
    "section": "Designing Tools",
    "text": "Designing Tools\n\nProcess the data using  tidyverse packages\nStatistical graphics must be prepared using ggplot2 and its extensions."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#version-1",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#version-1",
    "title": "Take-home Exercise 1",
    "section": "Version 1",
    "text": "Version 1\n\nLoading R Packages\nIn this hands-on exercise, two R packages will be used. They are:\n\ntidyverse ; and\nhaven\nggdist, for visualising distribution and uncertainty\nggridges, a ggplot2 extension specially designed for plotting ridgeline plots\nggthemes\ncolorspace\n\nThe code chunk used is as follows:\n\npacman::p_load(tidyverse,haven,ggdist, ggridges, ggthemes,\n               colorspace)\n\n\n\n\n\n\n\npacman::p_load() vs p_load()\n\n\n\n\n\nNote: using pacman::p_load() instead of p_load() allows us to use the p_load libary in pacman package even if pacman is not installed.\n\n\n\n\n\nPreparing SG dataset\nThe code chunk below uses read_sas() of haven to import PISA data into R envionment.\n\nstu_qqq &lt;- read_sas(\"data/cy08msp_stu_qqq.sas7bdat\")\n\n\n\n\n\n\n\nread_sas() vs read.sas()\n\n\n\n\n\nread_sas() is better than read.sas() because read_sas() conforms to tibbler dataframe and retains the column descriptions (aka column labels) in addition to just the variable names\n\n\n\nInterpreting the results: 613744 obs. of 1279 variables means there are 613744 observations, with 1279 columns in the data.\nUse the data explorer to filter CNT by SGP to get only Singapore data. Code chunk below allows us to filter by CNY = SGP\n\nstu_qqq_SG &lt;- stu_qqq %&gt;%\n  filter(CNT == \"SGP\")\n\nCode chunk below writes the filtered data into a .rds file\n\nwrite_rds(stu_qqq_SG, \"data/stu_qqq_SG.rds\")\n\nCode chunk below allows us to read the data from the .rds file so that we do have have to re-process from the main dataset everytime.\n\nstu_qqq_SG &lt;- read_rds(\"data/stu_qqq_SG.rds\")\n\n\n\nFields of interest\nThe suggested computation of ESCS score (i.e. economic, social and cultural status) in PISA 2022 is shown below, whereby HISEI refers to highest parental occupation status, PAREDINT refers to highest education of parent in years, HOMEPOS refers to home possessions.\n\n\n\nESCS Score computation\n\n\nThe fields of interest for socioeconomic status are:\n\nProfession: ST014/ST015 (Unfortunately not available in dataset)\nSchool education: ST005Q01JA (59) /ST007Q01JA (65)\nVocational Training: ST006/ST008\nHome Possessions: ST250, ST251, ST253, ST254, ST255, ST256\n\nBased on the PISA Data Analysis Manual, Fields of interest:\n\nPlausible value 1 to 10 in mathematics: PV1MATH, PV2MATH, …, PV10MATH\nPlausible value 1 to 10 in reading: PV1READ, PV2READ, … , PV10READ\nPlausible value 1 to 10 in science: PV1SCIE, PV2SCIE, …, PV10SCIE\n\nthe relationship between these performances with schools, gender and socioeconomic status of the students.\nFields of interest for gender: ST004D01T\nimmigrants and non-immigrants: fields 74,75,76, 77, 78, 79, 80, 81\n\nSchool ID: CNTSCHID\nStudent ID: CNTSTUID\n\nCode chunk below was used to view the field and field labels of the data\n\n# Extract labels\nvariable_labels &lt;- lapply(variable_names, function(var_name) {\n  attr(stu_qqq_SG[[var_name]], \"label\")\n# #attr_labels &lt;- labelled::labels(stu_qqq_SG[[var_name]])\n# if (!is.null(attr_labels)) {\n#  return(attr_labels$label)\n# } else {\n#  return(NULL)\n#}\n})\n\n\n# Extract variable names\n#variable_names &lt;- names(stu_qqq_SG)\ncol_names &lt;- as.list(colnames(stu_qqq_SG))\n\nCode chunk below was used to extract only a subset of the fields for analysis\n\ncol_name_regex_pv &lt;- \"PV\\\\d+READ|PV\\\\d+MATH|PV\\\\d+SCIE\" \ncol_name_regex_gender &lt;-\"ST004D01T\"\ncol_name_regex_school &lt;- \"CNTSCHID\"\ncol_name_regex_student_id &lt;- \"CNTSTUID\"\ncol_name_regex_profession &lt;- \"ST014*|ST015*\"\ncol_name_regex_education &lt;- \"ST005*|ST007*\"\ncol_name_regex_vocational_training &lt;- \"ST006|ST008\"\ncol_name_regex_home_possessions &lt;- \"ST250|ST251|ST253|ST254|ST255|ST256\"\n# Extract columns starting with \"PV*\"\n\ninterested_cols_regex &lt;- paste(col_name_regex_pv, col_name_regex_gender, col_name_regex_school,col_name_regex_student_id,col_name_regex_profession,col_name_regex_education,col_name_regex_vocational_training,col_name_regex_home_possessions, sep = \"|\")\n  \n#interested_cols_regex &lt;- paste(\"^(\",interested_cols_regex,\")\")\ncolumns_to_extract &lt;- grep(interested_cols_regex, colnames(stu_qqq_SG), value = TRUE)\n\nprint(columns_to_extract)\n\n [1] \"CNTSCHID\"   \"CNTSTUID\"   \"ST001D01T\"  \"ST003D02T\"  \"ST003D03T\" \n [6] \"ST004D01T\"  \"ST250Q01JA\" \"ST250Q02JA\" \"ST250Q03JA\" \"ST250Q04JA\"\n[11] \"ST250Q05JA\" \"ST250D06JA\" \"ST250D07JA\" \"ST251Q01JA\" \"ST251Q02JA\"\n[16] \"ST251Q03JA\" \"ST251Q04JA\" \"ST251Q06JA\" \"ST251Q07JA\" \"ST251D08JA\"\n[21] \"ST251D09JA\" \"ST253Q01JA\" \"ST254Q01JA\" \"ST254Q02JA\" \"ST254Q03JA\"\n[26] \"ST254Q04JA\" \"ST254Q05JA\" \"ST254Q06JA\" \"ST255Q01JA\" \"ST256Q01JA\"\n[31] \"ST256Q02JA\" \"ST256Q03JA\" \"ST256Q06JA\" \"ST256Q07JA\" \"ST256Q08JA\"\n[36] \"ST256Q09JA\" \"ST256Q10JA\" \"ST005Q01JA\" \"ST006Q01JA\" \"ST006Q02JA\"\n[41] \"ST006Q03JA\" \"ST006Q04JA\" \"ST006Q05JA\" \"ST007Q01JA\" \"ST008Q01JA\"\n[46] \"ST008Q02JA\" \"ST008Q03JA\" \"ST008Q04JA\" \"ST008Q05JA\" \"ST019AQ01T\"\n[51] \"ST019BQ01T\" \"ST019CQ01T\" \"ST016Q01NA\" \"PV1MATH\"    \"PV2MATH\"   \n[56] \"PV3MATH\"    \"PV4MATH\"    \"PV5MATH\"    \"PV6MATH\"    \"PV7MATH\"   \n[61] \"PV8MATH\"    \"PV9MATH\"    \"PV10MATH\"   \"PV1READ\"    \"PV2READ\"   \n[66] \"PV3READ\"    \"PV4READ\"    \"PV5READ\"    \"PV6READ\"    \"PV7READ\"   \n[71] \"PV8READ\"    \"PV9READ\"    \"PV10READ\"   \"PV1SCIE\"    \"PV2SCIE\"   \n[76] \"PV3SCIE\"    \"PV4SCIE\"    \"PV5SCIE\"    \"PV6SCIE\"    \"PV7SCIE\"   \n[81] \"PV8SCIE\"    \"PV9SCIE\"    \"PV10SCIE\"  \n\n# Subset the data frame to include only the selected columns\nsubset_fields_stu_qqq_SG &lt;- stu_qqq_SG[, columns_to_extract, drop = FALSE]\n\n# Print the subsetted data frame\nprint(subset_fields_stu_qqq_SG)\n\n# A tibble: 6,606 × 83\n   CNTSCHID CNTSTUID ST001D01T ST003D02T ST003D03T ST004D01T ST250Q01JA\n      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 70200052 70200001        10        10      2006         1          2\n 2 70200134 70200002        10         6      2006         2          1\n 3 70200112 70200003        10         7      2006         2          1\n 4 70200004 70200004        10         2      2006         2          2\n 5 70200152 70200005        10         9      2006         1          2\n 6 70200043 70200006        10         9      2006         1          2\n 7 70200049 70200007        10         3      2006         2          1\n 8 70200107 70200008        10         4      2006         2          1\n 9 70200012 70200009        10         8      2006         1          2\n10 70200061 70200010        10         6      2006         2          2\n# ℹ 6,596 more rows\n# ℹ 76 more variables: ST250Q02JA &lt;dbl&gt;, ST250Q03JA &lt;dbl&gt;, ST250Q04JA &lt;dbl&gt;,\n#   ST250Q05JA &lt;dbl&gt;, ST250D06JA &lt;chr&gt;, ST250D07JA &lt;chr&gt;, ST251Q01JA &lt;dbl&gt;,\n#   ST251Q02JA &lt;dbl&gt;, ST251Q03JA &lt;dbl&gt;, ST251Q04JA &lt;dbl&gt;, ST251Q06JA &lt;dbl&gt;,\n#   ST251Q07JA &lt;dbl&gt;, ST251D08JA &lt;chr&gt;, ST251D09JA &lt;chr&gt;, ST253Q01JA &lt;dbl&gt;,\n#   ST254Q01JA &lt;dbl&gt;, ST254Q02JA &lt;dbl&gt;, ST254Q03JA &lt;dbl&gt;, ST254Q04JA &lt;dbl&gt;,\n#   ST254Q05JA &lt;dbl&gt;, ST254Q06JA &lt;dbl&gt;, ST255Q01JA &lt;dbl&gt;, ST256Q01JA &lt;dbl&gt;, …\n\n#obtain the average PVs\nmath_pv_cols &lt;- grep(\"^PV\\\\d+MATH$\", colnames(subset_fields_stu_qqq_SG), value = TRUE)\n\n#print(math_pv_cols)\n\nsubset_fields_stu_qqq_SG$MATHS &lt;- rowMeans(subset_fields_stu_qqq_SG[, math_pv_cols, drop = FALSE], na.rm = TRUE)\n\n#READ\nread_pv_cols &lt;- grep(\"^PV\\\\d+READ$\", colnames(subset_fields_stu_qqq_SG), value = TRUE)\n\n# print(read_pv_cols)\n\nsubset_fields_stu_qqq_SG$READ &lt;- rowMeans(subset_fields_stu_qqq_SG[, read_pv_cols, drop = FALSE], na.rm = TRUE)\n\n#SCIENCE\nscience_pv_cols &lt;- grep(\"^PV\\\\d+SCIE$\", colnames(subset_fields_stu_qqq_SG), value = TRUE)\n\n# print(science_pv_cols)\n\nsubset_fields_stu_qqq_SG$SCIENCE &lt;- rowMeans(subset_fields_stu_qqq_SG[, science_pv_cols, drop = FALSE], na.rm = TRUE)\n\n\n# Print the updated data frame\n# print(subset_fields_stu_qqq_SG)\n\nCode chunk to display first 5 rows using head()\n\nhead(stu_qqq_SG,5) \n\n# A tibble: 5 × 1,279\n  CNT   CNTRYID CNTSCHID CNTSTUID CYC   NatCen STRATUM SUBNATIO REGION  OECD\n  &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 SGP       702 70200052 70200001 08MS  070200 SGP01   7020000   70200     0\n2 SGP       702 70200134 70200002 08MS  070200 SGP01   7020000   70200     0\n3 SGP       702 70200112 70200003 08MS  070200 SGP01   7020000   70200     0\n4 SGP       702 70200004 70200004 08MS  070200 SGP01   7020000   70200     0\n5 SGP       702 70200152 70200005 08MS  070200 SGP01   7020000   70200     0\n# ℹ 1,269 more variables: ADMINMODE &lt;dbl&gt;, LANGTEST_QQQ &lt;dbl&gt;,\n#   LANGTEST_COG &lt;dbl&gt;, LANGTEST_PAQ &lt;dbl&gt;, Option_CT &lt;dbl&gt;, Option_FL &lt;dbl&gt;,\n#   Option_ICTQ &lt;dbl&gt;, Option_WBQ &lt;dbl&gt;, Option_PQ &lt;dbl&gt;, Option_TQ &lt;dbl&gt;,\n#   Option_UH &lt;dbl&gt;, BOOKID &lt;dbl&gt;, ST001D01T &lt;dbl&gt;, ST003D02T &lt;dbl&gt;,\n#   ST003D03T &lt;dbl&gt;, ST004D01T &lt;dbl&gt;, ST250Q01JA &lt;dbl&gt;, ST250Q02JA &lt;dbl&gt;,\n#   ST250Q03JA &lt;dbl&gt;, ST250Q04JA &lt;dbl&gt;, ST250Q05JA &lt;dbl&gt;, ST250D06JA &lt;chr&gt;,\n#   ST250D07JA &lt;chr&gt;, ST251Q01JA &lt;dbl&gt;, ST251Q02JA &lt;dbl&gt;, ST251Q03JA &lt;dbl&gt;, …\n\n\n\n\nEDA Visualization\n\n#plot PV scores against gender\n\n# ggplot(data=exam_data, \n#        aes(x= MATHS)) +\n#   geom_histogram(bins=20) +\n#     facet_wrap(~ CLASS)\n\neda_data &lt;- subset_fields_stu_qqq_SG\nggplot(data=eda_data, \n       aes(x = MATHS)) +\n  geom_histogram(bins=20) +\n    facet_wrap(~ST004D01T) +\n    ggtitle(\"Maths score by gender\")\n\n\n\n\n\n\n\n# ) +\n#   geom_density_ridges(\n#     y = ST004D01T,\n#     scale = 3,\n#     rel_min_height = 0.01,\n#     bandwidth = 3.4,\n#     fill = lighten(\"#7097BB\", .3),\n#     color = \"white\"\n#   ) +\n  # scale_x_discrete(\n  #   name = \"Maths grades\",\n  #   expand = c(0, 0)\n  #   ) +\n  # scale_y_discrete(name = NULL, expand = expansion(add = c(0.2, 2.6))) +\n  # theme_ridges()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "https://public.tableau.com/app/profile/chow.hui.ling/viz/In-classExercise3-SuperstoreSalesandProfitReport_17063373718010/Dashboard1\nhttps://public.tableau.com/app/profile/chow.hui.ling/viz/In-classExercise3-SuperstoreSalesandProfitStory_17063377325780/SuperstoreSalesandProfitStory\nhttps://public.tableau.com/app/profile/chow.hui.ling/viz/In-classex03b-MathsvsEnglishScatterplotwithmarginalboxplot/Dashboard1"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#dashboard-stories-etc.-can-be-found-at",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#dashboard-stories-etc.-can-be-found-at",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "https://public.tableau.com/app/profile/chow.hui.ling/viz/In-classExercise3-SuperstoreSalesandProfitReport_17063373718010/Dashboard1\nhttps://public.tableau.com/app/profile/chow.hui.ling/viz/In-classExercise3-SuperstoreSalesandProfitStory_17063377325780/SuperstoreSalesandProfitStory\nhttps://public.tableau.com/app/profile/chow.hui.ling/viz/In-classex03b-MathsvsEnglishScatterplotwithmarginalboxplot/Dashboard1"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/chap20.html",
    "href": "In-class_Ex/In-class_Ex06/chap20.html",
    "title": "Time on the Horizon: ggHoriPlot methods",
    "section": "",
    "text": "A horizon graph is an analytical graphical method specially designed for visualising large numbers of time-series. It aims to overcome the issue of visualising highly overlapping time-series as shown in the figure below.\n\nA horizon graph essentially an area chart that has been split into slices and the slices then layered on top of one another with the areas representing the highest (absolute) values on top. Each slice has a greater intensity of colour based on the absolute value it represents.\n\nIn this section, you will learn how to plot a horizon graph by using ggHoriPlot package.\n\n\n\n\n\n\nTip\n\n\n\nBefore getting started, please visit Getting Started to learn more about the functions of ggHoriPlot package. Next, read geom_horizon() to learn more about the usage of its arguments."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/chap20.html#overview",
    "href": "In-class_Ex/In-class_Ex06/chap20.html#overview",
    "title": "Time on the Horizon: ggHoriPlot methods",
    "section": "",
    "text": "A horizon graph is an analytical graphical method specially designed for visualising large numbers of time-series. It aims to overcome the issue of visualising highly overlapping time-series as shown in the figure below.\n\nA horizon graph essentially an area chart that has been split into slices and the slices then layered on top of one another with the areas representing the highest (absolute) values on top. Each slice has a greater intensity of colour based on the absolute value it represents.\n\nIn this section, you will learn how to plot a horizon graph by using ggHoriPlot package.\n\n\n\n\n\n\nTip\n\n\n\nBefore getting started, please visit Getting Started to learn more about the functions of ggHoriPlot package. Next, read geom_horizon() to learn more about the usage of its arguments."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/chap20.html#getting-started",
    "href": "In-class_Ex/In-class_Ex06/chap20.html#getting-started",
    "title": "Time on the Horizon: ggHoriPlot methods",
    "section": "Getting started",
    "text": "Getting started\nBefore getting start, make sure that ggHoriPlot has been included in the pacman::p_load(...) statement above.\n\n\nShow the code\npacman::p_load(ggHoriPlot, ggthemes, tidyverse)\n\n\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, Average Retail Prices Of Selected Consumer Items will be used.\nUse the code chunk below to import the AVERP.csv file into R environment.\n\naverp &lt;- read_csv(\"data/AVERP.csv\") %&gt;%\n  mutate(`Date` = dmy(`Date`))\n\n\n\n\n\n\n\nThing to learn from the code chunk above.\n\n\n\n\nBy default, read_csv will import data in Date field as Character data type. dmy() of lubridate package to palse the Date field into appropriate Date data type in R.\n\n\n\n\n\n\nStep 2: Plotting the horizon graph\nNext, the code chunk below will be used to plot the horizon graph.\n\naverp %&gt;% \n  filter(Date &gt;= \"2018-01-01\") %&gt;%\n  ggplot() +\n  geom_horizon(aes(x = Date, y=Values), \n               origin = \"midpoint\", \n               horizonscale = 6)+\n  facet_grid(`Consumer Items`~.) +\n    theme_few() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  ggtitle('Average Retail Prices of Selected Consumer Items (Jan 2018 to Dec 2022)')"
  }
]