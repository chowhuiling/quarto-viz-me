---
title: "In-Class Ex07 - IsoMap"
author: "Chow Hui Ling"
date: "09 Mar 2024"
date-modified: "last-modified"
date-format: "DD MMM YYYY"

execute: 
  eval: true
  echo: true
  freeze: true # doesn't re-render the page if there are no changes to the page
  warning: false
  message: false
---

# Overview

In this in-class exercise, we want to build an isohyet map to visualize the rainfall of different locations using a map like below.

![Reference: https://isss608-vaa-demo.netlify.app/in-class_ex/in-class_ex07/image/image1.png](https://isss608-vaa-demo.netlify.app/in-class_ex/in-class_ex07/image/image1.png)

In order to prepare an isohyet map, spatial interpolation will be used to estimate the values at other points (outside of the weather stations) where we do not have any datapoints. This type of interpolated surface is often called a **geostatistical surface**.

There are many interpolation methods. In this hands-on exercise, two widely used spatial interpolation methods called Inverse Distance Weighting (IDW) and kriging will be used.

## Data Used

All data is in `data/aspatial` and `data/geospatial` folders.

-   *data/aspatial/RainfallStation.csv* provides location information of existing rainfall stations in Singapore. The data is downloaded from [Meteological Service Singapore](http://www.weather.gov.sg/home/).

-   *data/aspatial/DAILYDATA_202402.csv* provides weather data are rainfall stations for the month February, 2024. The data is also downloaded from [Meteological Service Singapore](http://www.weather.gov.sg/home/).

-   *data/geospatial/MPSZ-2019* contains planning subzone boundary of URA Master Plan 2019. It is downloaded from data.gov.sg. The original data is in kml format.

## Libraries Used

-   tmap is used for mapping purposes

-   viridis is a colour library to provide tmap more colours to use

-   tidyverse is for data wrangling

-   sf allows us to do data import

-   [terra](https://rspatial.github.io/terra/) allows us to handle raster data and convert it into a raster map. It is faster than the raster package, but has a simpler interface and is faster than raster.

-   [gstat](http://r-spatial.github.io/gstat/) is for spatial interpolation to make it smoother (It is also used to create the geostatistical modelling, prediction and simulation)

-   [automap](https://cran.r-project.org/web/packages/automap/) is for performing automatic variogram modelling and kriging interpolation.

```{r}
pacman::p_load(sf, terra, gstat, automap, tmap, viridis, tidyverse)
```

# Read Data from csv

```{r}
rfstations <- read_csv("data/aspatial/RainfallStation.csv")
```

We note that the rainfall data probably uses WGS 84 geographic coordinate system of Singapore

```{r}
rfdata <- read_csv("data/aspatial/DAILYDATA_202402.csv") %>%
  select(c(1, 5)) |> #select only columns 1 and 5
  group_by(Station) |>
  summarise(MONTHSUM = sum(`Daily Rainfall Total (mm)`)) %>%
  ungroup()
```

```{r}
rfdata <- rfdata |>
  left_join(rfstations) #join to get the latlng
```

Notice that the Latitude and Longitude are added to rfdata. We didn't have to specify the column name to join by because the data had been pre-cleaned to rename to have the same column name "`Station`"

We screen through the data to ensure there is no NA or null records (ensure all have proper Latitude and Longtitude data for plotting on our map)

```{r}
rfdata_sf <- st_as_sf(rfdata,
                      coords = c("Longitude",  #we put x-axis (longitude) then y-axis (Latitude) into a coordinate pair
                                 "Latitude"),
                      crs = 4326)  %>% #4326 represents WGS84 projection system which source data is using
                      st_transform(crs = 3414) #transform to coordinate system so we can  svy21, which is the official projected coordinates of Singapore. 3414 is the EPSG code of svy21. use metre
                        
```

In the code chunk below, `st_read()` of sf package is used to import MPSZ-2019 shapefile into R. The output is called mpsz2019. It is in polygon feature tibble data.frame format

```{r}
mpsz2019 <- st_read(dsn = "data/geospatial",
                    layer = "MPSZ-2019") %>%
  st_transform(crs=3414)
```

Note:

-   The source data is in wgs84 coordinates system, hence `st_tranform()` of **sf** package is used to transform output sf data.frame into svy21 project coordinates system.

# Visualising the data prepared

-   tm_polygons() is a combination of tm_fill() and tm_borders(). In the following code, we only plot the border without using the fill() portion.

```{r}
tmap_options(check.and.fix = TRUE)
tmap_mode("view")
tm_shape(rfdata_sf) +
  tm_dots(col="red")
```

\`\`\`

```{r}
tmap_mode("plot")
```

In the code chunk below, tmap functionsi are used to create a quantitative dot map of rainfall distribution by rainfall station in Singapore

```{r}
tmap_options(check.and.fix = TRUE) #this doesn't change raw data, just ignores the error data
tmap_mode("view") #plot the interactive version
dots_only_plot <- tm_shape(mpsz2019) +
  tm_borders() +  # we're using it as a background only, ensure the points are not covered
tm_shape(rfdata_sf) +
  tm_dots(col = 'MONTHSUM')

dots_only_plot
#tmap_mode("plot")

```
# Spatial Interpolation with `gstat` method
In the next section, we will perform spatial interpolation by using gstat package. In order to perform spatial interpolation by using gstat, we first need to create an object of class called *gstat*, using a function of the same name: `gstat`. A gstat object contains all necessary info to conduct spatial interpolation, namely:

-   model definition

-   calibration data

Based on its arguments, the gstat function "understand " what type of interpolation model we want to use.

-   No variogram model -\> IDW

-   Variogram model, no covariates -\> Original Kriging

-   Variogram model, with covariates -\> Universal Kriging

The complete decision tree of gstat, including several additional methods which we are not going to use, is shown in the figure below.

![Source: https://isss608-vaa-demo.netlify.app/in-class_ex/in-class_ex07/image/image4.png](img/image4.png)

## Data Preparation

To get started, we need to create a grid data object by using `rast()` of **terra** package as shown in the code chunk below.

```{r}
#nrows and ncols are obtained from max - min of the coordinates in mpsz2019 data, then divide by the (length of) the chosen rastor resolution
grid <- terra::rast(mpsz2019,
                    nrows = 690,
                    ncols = 1075)
grid
```

Next, a list called xy will be created by using `xyFromCell()` of **terra** package

```{r}
xy <- terra::xyFromCell(grid,
                        1:ncell(grid)
                        )
head(xy)
```

Note: `xyFromCell()` gets coordinates of the center of raster cells for a row, column or cell number of a SpatRaster. Or get row,column or cell numbers fro coordinates or from each other.

Lastly, we will create a dataframe called *coop* with prediction/simulation locations by using the code chunk below.

```{r}
coop <- st_as_sf(as.data.frame(xy),
                 coords = c("x", "y"),
                 crs = st_crs(mpsz2019))
#head(coop)
coop <- st_filter(coop, mpsz2019)
head(coop)

```

# Using IDW

In IDW interpolation, sample points are weighted based on how near the sample points are from it. Weighting is assigned to sample points through weighting coefficients that controls how weighting influence will drop off as the distance from new point increases. The greater the weighting coefficient, the less the effect points will have if they are far from the unknown point during the interpolation process. As the coefficient increases, the value of the unknown point approaches the value of the nearest observational point.

It is important to note that the IDW interpolation method also has some disadvantages: the quality of the interpolation result can decrease, if the distribution of sample data points is uneven. Further, max and min values in the interpolated surface can only occur at sample data points. This often results in small peaks and pits around the sample data points.

## Working with gstat

we are going to use three parameters of the gstat function: - formula: the prediction formula specifying the dependent and the independent variables (covariates) - data: the calibration data - model: the variogram model

keep in mind that we need to specify parameter names, because these three parameters are not the first 3 in the gstat function definition.

to interpolate usin gIDW method, we create the following gstat object, specifying just the formula and data:

```{r}
g = gstat(formula = annual ~ 1, data = rfdata_sf)
```

Note: - "\~" is used to create the formula object, which specifies the relationship between the names of dependent variables (on the left of the \~ symbol) and independent variables (to the right of the symbol). Writing 1 to the right of the \~ symbol, as in \~ 1, means that there are no independent variables.

In the code chunk below,

```{r}
res <- gstat(formula = MONTHSUM~1,
             locations = rfdata_sf,
             nmax = 5, #we want to count 5 neighbors
             set = list(idp = 0))
```

::: callout-note
we can also change the nmax (this will make our eventual map look quite different)
:::

Now that our model is defined, we can use `predict()` to actually interpolate, i.e. to calculate predicted values. The predict function accepts:

-   a raster
-   stars object, such as dem
-   a model
-   gstat object, such as g

The raster serves for 2 purposes: - specifying the locations where we want to make predictions (in all methods), nd - specifying covariate values (in Universal Kriging only).

```{r}
resp <- predict(res,coop)

## [inverse distance weighted interpolation]

resp$x <- st_coordinates(resp)[,1]
resp$y <- st_coordinates(resp)[,2]
resp$pred <- resp$var1.pred

pred <- terra::rasterize(resp,grid,
                         field="pred",
                         fun="mean")
```

Now we will map the interpolated surface by using tmap functions as shown in the code chunk below.

```{r}
tmap_options(check.and.fix = TRUE)
tmap_mode("plot")
idw_plot <- tm_shape(pred) +
  tm_raster(alpha = 0.6,
            palette = "viridis")

idw_plot
```

# Kriging

## The method

Kriging is one of several methods that use a limited set of sampled data points to estimate the value of a variable over a continuous spatial field. An example of a value that varies across a random spatial field might be total monthly rainfall over Singapore. It differs from the Inverse Distance Weighted Interpolation earlier in that it uses the spatial correlation between sampled points to interpolate the values in the spatial field: The interpolation is based on the spatial arrangement of the empirical observations, rather than on a presumed model of spatial distribution. Kriging also generates estimates of the uncertainty surrounding each interpolated value.

In a general sense, the kriging weights are calculated such that points nearby to the location of interest are given more weight than those farther away. Clustering of points is also taken into account, so that clusters of points are weighted less heavily (in effect, they contain less information than single points). This helps to reduce bias in the predictions.

The kriging predictor is an “optimal linear predictor” and an exact interpolator, meaning that each interpolated value is calculated to minimize the prediction error for that point. The value that is generated from the kriging process for any actually sampled location will be equal to the observed value at this point, and all the interpolated values will be the Best Linear Unbiased Predictors (BLUPs).

Kriging will in general not be more effective than simpler methods of interpolation if there is little spatial autocorrelation among the sampled data points (that is, if the values do not co-vary in space). If there is at least moderate spatial autocorrelation, however, kriging can be a helpful method to preserve spatial variability that would be lost using a simpler method (for an example, see Auchincloss 2007, below).

Kriging can be understood as a two-step process:

first, the spatial covariance structure of the sampled points is determined by fitting a variogram; and second, weights derived from this covariance structure are used to interpolate values for unsampled points or blocks across the spatial field.

Kriging methods require a variogram model. A variogram (sometimes called a “semivariogram”) is a visual depiction of the covariance exhibited between each pair of points in the sampled data. For each pair of points in the sampled data, the gamma-value or “semi-variance” (a measure of the half mean-squared difference between their values) is plotted against the distance, or “lag”, between them. The “experimental” variogram is the plot of observed values, while the “theoretical” or “model” variogram is the distributional model that best fits the data.

![Source:https://isss608-vaa-demo.netlify.app/in-class_ex/in-class_ex07/image/image5.png](img/image5.png) \## Working with **gstat** Firstly, we will calculate and examine the empirical variogram by using `variogram()` of **gstat** package. The function requires two arguments: - formula, the dependent variable and covariates (same as the above section) - data, a point layer with the dependent variable and covariates as attribute.

```{r}
v <- variogram(MONTHSUM ~ 1,
               data = rfdata_sf) #to plot statistics

plot(v)
```

We will then compare the plot with the theoretical models below: ![Source: https://isss608-vaa-demo.netlify.app/in-class_ex/in-class_ex07/In-class_Ex07-IsoMap_files/figure-html/unnamed-chunk-16-1.png](img/theoretical-variogram.png) With reference to the comparison above, an empirical variogram model will be fitted by using `fit.variogram()` of **gstat** package as shown below:

fit to fit the model,

```{r}
fv <- fit.variogram(object = v,
                    model = vgm(psill = 0.5,
                                model = "Sph",  
                                range = 5000,
                                nugget = 0.1))
fv


#plot the graph to visualize the fit
plot(v,fv)
```

::: callout-danger
We need to try to explore the above method by changing `psill`, `model`, `range`, `nugget` arguments to understand how the surface map will be affected by different options used.

For E.g., we might find that psill doesn't affect the chart, so we should not expose this to the users
:::

Once we find the model that fits rather well, we will go ahead to perform spatial interpolation by using the newly derived model as shown in the code chunk below:

```{r}
k <- gstat(formula = MONTHSUM ~ 1,
           data = rfdata_sf,
           model = fv)
k
```

Once we are happy with the results, predict() of gstat package will be used to estimate the unknown grids by using the code chink below.

```{r}
resp <- predict(k,coop)

#[using ordinary kriging]
resp$x <- st_coordinates(resp)[,1]
resp$y <- st_coordinates(resp)[,2]
resp$pred <- resp$var1.pred
resp$pred <- resp$pred
resp


```

::: callout-note
*resp* is a sf tibble data.frame with point features.
:::

In order to create a raster surface data object, rasterize() of terra is used as shown in the code chunk below

```{r}
kpred <- terra::rasterize(resp, grid, field="pred")

kpred
```

::: callout-note
The output object kpred is in SpatRaster object class with a spatial resolution of 50m x 50m. It consists of 1075 columns and 690 rows and in SVY21 project coordinate system.
:::

## Mapping the interpolated rainfall raster (i.e. kpred) by using the code chunk below

```{r}
tmap_options(check.and.fix = TRUE)
tmap_mode("plot")
variogram_plot <- tm_shape(kpred) + 
  tm_raster(alpha = 0.6,
            palette = "viridis",
            title = "Total monthly rainfall (mm)") +
  tm_layout(main.title = "Distribution of monthly rainfall",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45,
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2) + 
  tm_scale_bar() + 
  tm_grid(alpha = 0.2)

variogram_plot

```

## Automatic variogram modelling

Besides using gstat to perform variogram modelling manually, `autofitVariogram()` of **automap** package can be used to perform variogram modelling as shown in code chunk below.

```{r}
v_auto <- autofitVariogram(MONTHSUM ~ 1, rfdata_sf)
plot(v_auto)


v_auto





```

```{r}
#  draw best fit line
k <- gstat(formula = MONTHSUM ~ 1,
           model = v_auto$var_model,
           data = rfdata_sf)
k


resp_auto <- predict(k, coop)

# [using ordinary krigging]
resp_auto$x <- st_coordinates(resp)[,1]
resp_auto$y <- st_coordinates(resp)[,2]
resp_auto$pred <- resp_auto$var1.pred
resp_auto$pred <- resp_auto$pred

kpred <- terra::rasterize(resp_auto, grid, 
                         field = "pred")

tmap_options(check.and.fix = TRUE)
tmap_mode("plot")
autov_plot <- tm_shape(kpred) + 
  tm_raster(alpha = 0.6, 
            palette = "viridis",
            title = "Total monthly rainfall (mm)") +
  tm_layout(main.title = "Distribution of monthly rainfall, Feb 2024",
            main.title.position = "center",
            main.title.size = 1.2,
            legend.height = 0.45, 
            legend.width = 0.35,
            frame = TRUE) +
  tm_compass(type="8star", size = 2) +
  tm_scale_bar() +
  tm_grid(alpha =0.2)


autov_plot
```

# Comparing all 3 geostatistical plots 
```{r}
#| layout-ncol: 3
#| fig-cap:
#|  - "Inverse Distance Weighting (IDW)"
#|  - "Kriging with auto-fit variogram"
#|  - "Kriging with manual variogram"

## IDW plot
idw_plot + dots_only_plot

## auto fit variogram
autov_plot + dots_only_plot

## variogram
dots_only_plot + variogram_plot 




```
We notice that the manual-variogram seems to provide a nicer and smoother statistical variation for areas without sampling.

# Miscellaneous Notes

-   **%\>% allows you to drop the parentheses when calling a function with no other arguments; \|\> always requires the parentheses**. %\>% allows you to start a pipe with . to create a function rather than immediately executing the pipe; this is not supported by the base pipe

# Reference

<https://isss608-vaa-demo.netlify.app/in-class_ex/in-class_ex07/in-class_ex07-isomap>
